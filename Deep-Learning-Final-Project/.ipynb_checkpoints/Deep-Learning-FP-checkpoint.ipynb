{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f29ab6e8",
   "metadata": {},
   "source": [
    "# Deep Learning Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b1d2e5",
   "metadata": {},
   "source": [
    "Data downloaded from Kaggle.com: https://www.kaggle.com/datasets/johnbergmann/captcha-image-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "254de932",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 16:31:08.187899: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a109039",
   "metadata": {},
   "source": [
    "Download captcha dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e62f7db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle datasets download -d johnbergmann/captcha-image-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33479af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip captcha-image-dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e92702d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500\r\n"
     ]
    }
   ],
   "source": [
    "!ls captchas/test/*.jpeg | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095d188f",
   "metadata": {},
   "source": [
    "Convert the jpegs to a dataframe and take the label from the filename for the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1529ae34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8501, 50, 250, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define path to training set\n",
    "path = \"./captchas/train/\"\n",
    "\n",
    "# get a list of the file names\n",
    "filenames = glob.glob(\"*.jpeg\", root_dir=path)\n",
    "\n",
    "# Number of samples and the number of features\n",
    "n_train = len(filenames)\n",
    "with Image.open(path+filenames[0]) as im:\n",
    "    w, h = im.size\n",
    "\n",
    "# Transform it into raw data\n",
    "X_train = np.zeros((n_train, h, w, 1))\n",
    "labels_train = np.zeros(n_train, dtype=object)\n",
    "for filename in filenames:\n",
    "    # Get the label from the filename\n",
    "    idx, label = filename[:-5].split(\"_\")\n",
    "    idx = int(idx)\n",
    "    labels_train[idx] = label.upper()\n",
    "    \n",
    "    # Get the pixel data from the image\n",
    "    with Image.open(path+filename) as im:\n",
    "        # Convert to grayscale\n",
    "        im = im.convert('L')\n",
    "        X_train[idx] = np.array(im).reshape(h,w,1)\n",
    "        \n",
    "X_train /= 255\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996756db",
   "metadata": {},
   "source": [
    "Let's look at one of the captchas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50897bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=250x50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_im(pixels):\n",
    "    if pixels.shape[-1] == 1:\n",
    "        pixels = pixels.reshape(pixels.shape[:-1])\n",
    "    im = Image.fromarray(np.uint8(pixels*255))\n",
    "    im.show()\n",
    "    \n",
    "show_im(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80f94de",
   "metadata": {},
   "source": [
    "Transform the labels into each character and separate by character position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "798b7685",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53d940be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train = np.array([list(label) for label in labels_train], dtype=object)\n",
    "\n",
    "y_train = {}\n",
    "encoders = {}\n",
    "for i in range(labels_train.shape[1]):\n",
    "    y_train[i] = encoder.fit_transform(labels_train[:,i].reshape(-1,1))\n",
    "    \n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0324e854",
   "metadata": {},
   "source": [
    "Do the same for `X_test` and `y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a679c87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 50, 250, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define path to training set\n",
    "path = \"./captchas/test/\"\n",
    "\n",
    "# get a list of the file names\n",
    "filenames = glob.glob(\"*.jpeg\", root_dir=path)\n",
    "\n",
    "# Number of samples and the number of features\n",
    "n_test = len(filenames)\n",
    "with Image.open(path+filenames[0]) as im:\n",
    "    w, h = im.size\n",
    "\n",
    "# Transform it into raw data\n",
    "X_test = np.zeros((n_test, h, w, 1))\n",
    "labels_test = np.zeros(n_test, dtype=object)\n",
    "for filename in filenames:\n",
    "    # Get the label from the filename\n",
    "    idx, label = filename[:-5].split(\"_\")\n",
    "    idx = int(idx) - n_train \n",
    "    labels_test[idx] = label.upper()\n",
    "    \n",
    "    # Get the pixel data from the image\n",
    "    with Image.open(path+filename) as im:\n",
    "        # Convert to grayscale\n",
    "        im = im.convert('L')\n",
    "        X_test[idx] = np.array(im).reshape(h,w,1)\n",
    "        \n",
    "X_test /= 255\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c48574d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_test = np.array([list(label) for label in labels_test], dtype=object)\n",
    "\n",
    "y_test = {}\n",
    "for i in range(labels_test.shape[1]):\n",
    "    y_test[i] = encoder.transform(labels_test[:,i].reshape(-1,1))\n",
    "    \n",
    "y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4c7bce",
   "metadata": {},
   "source": [
    "Build a basic model for identifying the first character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b22373ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 25, 125, 32)       832       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 12, 62, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 23808)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                1523776   \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 21)                1365      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,525,973\n",
      "Trainable params: 1,525,973\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "n_classes = y_train[0].shape[1]\n",
    "\n",
    "# Simple CNN\n",
    "model_1 = Sequential()\n",
    "\n",
    "# Convolutional layer with 32 filters and size 5x5 and stride 2\n",
    "model_1.add(Conv2D(32, 5, strides=2, padding='same', \n",
    "                   activation='relu', input_shape=X_train.shape[1:]))\n",
    "\n",
    "# MaxPooling layer with size 2\n",
    "model_1.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "# Flatten the data and feed into dense layers\n",
    "model_1.add(Flatten())\n",
    "model_1.add(Dense(64, activation='relu'))\n",
    "model_1.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe180873",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f493617",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "133/133 [==============================] - 16s 115ms/step - loss: 3.0731 - accuracy: 0.0468 - val_loss: 3.0446 - val_accuracy: 0.0453\n",
      "Epoch 2/15\n",
      "133/133 [==============================] - 16s 118ms/step - loss: 3.0439 - accuracy: 0.0526 - val_loss: 3.0447 - val_accuracy: 0.0453\n",
      "Epoch 3/15\n",
      "133/133 [==============================] - 15s 110ms/step - loss: 3.0436 - accuracy: 0.0526 - val_loss: 3.0449 - val_accuracy: 0.0453\n",
      "Epoch 4/15\n",
      "133/133 [==============================] - 15s 113ms/step - loss: 3.0433 - accuracy: 0.0526 - val_loss: 3.0449 - val_accuracy: 0.0453\n",
      "Epoch 5/15\n",
      "133/133 [==============================] - 15s 112ms/step - loss: 3.0432 - accuracy: 0.0526 - val_loss: 3.0452 - val_accuracy: 0.0453\n",
      "Epoch 6/15\n",
      "133/133 [==============================] - 15s 113ms/step - loss: 3.0431 - accuracy: 0.0526 - val_loss: 3.0453 - val_accuracy: 0.0453\n",
      "Epoch 7/15\n",
      "133/133 [==============================] - 14s 108ms/step - loss: 3.0430 - accuracy: 0.0526 - val_loss: 3.0454 - val_accuracy: 0.0453\n",
      "Epoch 8/15\n",
      "133/133 [==============================] - 14s 108ms/step - loss: 3.0430 - accuracy: 0.0526 - val_loss: 3.0455 - val_accuracy: 0.0453\n",
      "Epoch 9/15\n",
      "133/133 [==============================] - 15s 115ms/step - loss: 3.0429 - accuracy: 0.0526 - val_loss: 3.0456 - val_accuracy: 0.0453\n",
      "Epoch 10/15\n",
      "133/133 [==============================] - 16s 118ms/step - loss: 3.0429 - accuracy: 0.0526 - val_loss: 3.0457 - val_accuracy: 0.0453\n",
      "Epoch 11/15\n",
      "133/133 [==============================] - 12s 91ms/step - loss: 3.0429 - accuracy: 0.0526 - val_loss: 3.0457 - val_accuracy: 0.0453\n",
      "Epoch 12/15\n",
      "133/133 [==============================] - 14s 102ms/step - loss: 3.0429 - accuracy: 0.0526 - val_loss: 3.0458 - val_accuracy: 0.0453\n",
      "Epoch 13/15\n",
      "133/133 [==============================] - 16s 118ms/step - loss: 3.0429 - accuracy: 0.0526 - val_loss: 3.0458 - val_accuracy: 0.0453\n",
      "Epoch 14/15\n",
      "133/133 [==============================] - 13s 101ms/step - loss: 3.0429 - accuracy: 0.0526 - val_loss: 3.0459 - val_accuracy: 0.0453\n",
      "Epoch 15/15\n",
      "133/133 [==============================] - 15s 112ms/step - loss: 3.0429 - accuracy: 0.0526 - val_loss: 3.0459 - val_accuracy: 0.0453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7faec8d864d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_pos = 0\n",
    "model_1.fit(X_train, y_train[char_pos],\n",
    "              batch_size=64,\n",
    "              epochs=15,\n",
    "              validation_data=(X_test, y_test[char_pos]),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d422b460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 1s 17ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39288a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 21)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "573bdc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate into 0s and 1s so it can be back transformed by encoder\n",
    "def pred_classes(y_pred):\n",
    "    classes = np.argmax(y_pred, axis=1)\n",
    "    y_pred = np.zeros_like(y_pred)\n",
    "    \n",
    "    for i in range(len(y_pred)):\n",
    "        y_pred[i, classes[i]] = 1\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "# y_pred = pred_classes(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f92122f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'P', 'N', ..., 'G', 'B', 'R'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.inverse_transform(y_pred).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0b5e56aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'P', 'N', ..., 'G', 'H', 'R'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.inverse_transform(y_test[0]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4181729e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all models\n",
    "\n",
    "def train_model(X_train, X_test, y_train, y_test):\n",
    "    # Clear the current model\n",
    "    keras.backend.clear_session()\n",
    "    \n",
    "    n_classes = y_train.shape[1]\n",
    "\n",
    "    # Simple CNN\n",
    "    model = Sequential()\n",
    "\n",
    "    # Convolutional layer with 32 filters and size 5x5 and stride 2\n",
    "    model.add(Conv2D(32, 5, strides=2, padding='same', activation='relu',\n",
    "                     input_shape=X_train.shape[1:]))\n",
    "    \n",
    "    # Convolutional layer with 32 filters and size 5x5 and stride 2\n",
    "    model.add(Conv2D(32, 5, strides=2, padding='same', activation='relu'))\n",
    "    \n",
    "    # MaxPooling layer with size 2\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # Flatten the data and feed into dense layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(X_train, y_train,\n",
    "                  batch_size=64,\n",
    "                  epochs=15,\n",
    "                  validation_data=(X_test, y_test),\n",
    "                  shuffle=True)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3180bbe3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 25, 125, 32)       832       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 12, 62, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 12, 62, 32)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 23808)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                1523776   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 21)                1365      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,525,973\n",
      "Trainable params: 1,525,973\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "133/133 [==============================] - 17s 122ms/step - loss: 3.0517 - accuracy: 0.0529 - val_loss: 3.0269 - val_accuracy: 0.0587\n",
      "Epoch 2/15\n",
      "133/133 [==============================] - 16s 117ms/step - loss: 2.8094 - accuracy: 0.1457 - val_loss: 2.4038 - val_accuracy: 0.2667\n",
      "Epoch 3/15\n",
      "133/133 [==============================] - 17s 125ms/step - loss: 1.8990 - accuracy: 0.4024 - val_loss: 1.6949 - val_accuracy: 0.4420\n",
      "Epoch 4/15\n",
      "133/133 [==============================] - 17s 126ms/step - loss: 1.2797 - accuracy: 0.5978 - val_loss: 1.3685 - val_accuracy: 0.5733\n",
      "Epoch 5/15\n",
      "133/133 [==============================] - 16s 122ms/step - loss: 0.9569 - accuracy: 0.7044 - val_loss: 1.1583 - val_accuracy: 0.6207\n",
      "Epoch 6/15\n",
      "133/133 [==============================] - 15s 112ms/step - loss: 0.7441 - accuracy: 0.7737 - val_loss: 1.1229 - val_accuracy: 0.6500\n",
      "Epoch 7/15\n",
      "133/133 [==============================] - 16s 122ms/step - loss: 0.5994 - accuracy: 0.8211 - val_loss: 1.0275 - val_accuracy: 0.6847\n",
      "Epoch 8/15\n",
      "133/133 [==============================] - 16s 118ms/step - loss: 0.4879 - accuracy: 0.8559 - val_loss: 0.9870 - val_accuracy: 0.7100\n",
      "Epoch 9/15\n",
      "133/133 [==============================] - 15s 112ms/step - loss: 0.4017 - accuracy: 0.8830 - val_loss: 0.9591 - val_accuracy: 0.7100\n",
      "Epoch 10/15\n",
      "133/133 [==============================] - 15s 116ms/step - loss: 0.3269 - accuracy: 0.9119 - val_loss: 0.8837 - val_accuracy: 0.7473\n",
      "Epoch 11/15\n",
      "133/133 [==============================] - 16s 120ms/step - loss: 0.2745 - accuracy: 0.9217 - val_loss: 0.8968 - val_accuracy: 0.7540\n",
      "Epoch 12/15\n",
      "133/133 [==============================] - 15s 117ms/step - loss: 0.2334 - accuracy: 0.9366 - val_loss: 0.8967 - val_accuracy: 0.7520\n",
      "Epoch 13/15\n",
      "133/133 [==============================] - 16s 121ms/step - loss: 0.1875 - accuracy: 0.9529 - val_loss: 0.8547 - val_accuracy: 0.7767\n",
      "Epoch 14/15\n",
      "133/133 [==============================] - 15s 115ms/step - loss: 0.1686 - accuracy: 0.9579 - val_loss: 0.8859 - val_accuracy: 0.7720\n",
      "Epoch 15/15\n",
      "133/133 [==============================] - 16s 120ms/step - loss: 0.1487 - accuracy: 0.9632 - val_loss: 0.8944 - val_accuracy: 0.7733\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 25, 125, 32)       832       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 12, 62, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 12, 62, 32)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 23808)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                1523776   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 21)                1365      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,525,973\n",
      "Trainable params: 1,525,973\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "133/133 [==============================] - 15s 114ms/step - loss: 3.0568 - accuracy: 0.0628 - val_loss: 3.0068 - val_accuracy: 0.0667\n",
      "Epoch 2/15\n",
      "133/133 [==============================] - 16s 120ms/step - loss: 2.7970 - accuracy: 0.1627 - val_loss: 2.5022 - val_accuracy: 0.2753\n",
      "Epoch 3/15\n",
      "133/133 [==============================] - 15s 112ms/step - loss: 2.1174 - accuracy: 0.3524 - val_loss: 2.0601 - val_accuracy: 0.3700\n",
      "Epoch 4/15\n",
      "133/133 [==============================] - 15s 115ms/step - loss: 1.6291 - accuracy: 0.4924 - val_loss: 1.7923 - val_accuracy: 0.4573\n",
      "Epoch 5/15\n",
      "133/133 [==============================] - 15s 116ms/step - loss: 1.2967 - accuracy: 0.5984 - val_loss: 1.6520 - val_accuracy: 0.4847\n",
      "Epoch 6/15\n",
      "133/133 [==============================] - 16s 123ms/step - loss: 1.0800 - accuracy: 0.6619 - val_loss: 1.5424 - val_accuracy: 0.5133\n",
      "Epoch 7/15\n",
      "133/133 [==============================] - 15s 117ms/step - loss: 0.9098 - accuracy: 0.7205 - val_loss: 1.4180 - val_accuracy: 0.5760\n",
      "Epoch 8/15\n",
      "133/133 [==============================] - 15s 115ms/step - loss: 0.7677 - accuracy: 0.7604 - val_loss: 1.4114 - val_accuracy: 0.5967\n",
      "Epoch 9/15\n",
      "133/133 [==============================] - 16s 123ms/step - loss: 0.6490 - accuracy: 0.8050 - val_loss: 1.3799 - val_accuracy: 0.6147\n",
      "Epoch 10/15\n",
      "133/133 [==============================] - 16s 118ms/step - loss: 0.5630 - accuracy: 0.8321 - val_loss: 1.3664 - val_accuracy: 0.6233\n",
      "Epoch 11/15\n",
      "133/133 [==============================] - 17s 125ms/step - loss: 0.4862 - accuracy: 0.8565 - val_loss: 1.3141 - val_accuracy: 0.6507\n",
      "Epoch 12/15\n",
      "133/133 [==============================] - 16s 122ms/step - loss: 0.4284 - accuracy: 0.8743 - val_loss: 1.3650 - val_accuracy: 0.6407\n",
      "Epoch 13/15\n",
      "133/133 [==============================] - 15s 111ms/step - loss: 0.3548 - accuracy: 0.9012 - val_loss: 1.3560 - val_accuracy: 0.6533\n",
      "Epoch 14/15\n",
      "133/133 [==============================] - 15s 111ms/step - loss: 0.3146 - accuracy: 0.9110 - val_loss: 1.3552 - val_accuracy: 0.6687\n",
      "Epoch 15/15\n",
      "133/133 [==============================] - 16s 119ms/step - loss: 0.2757 - accuracy: 0.9251 - val_loss: 1.4047 - val_accuracy: 0.6660\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 25, 125, 32)       832       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 12, 62, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 12, 62, 32)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 23808)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                1523776   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 21)                1365      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,525,973\n",
      "Trainable params: 1,525,973\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "133/133 [==============================] - 17s 126ms/step - loss: 3.0597 - accuracy: 0.0495 - val_loss: 3.0426 - val_accuracy: 0.0507\n",
      "Epoch 2/15\n",
      "133/133 [==============================] - 15s 110ms/step - loss: 3.0252 - accuracy: 0.0613 - val_loss: 3.0185 - val_accuracy: 0.0640\n",
      "Epoch 3/15\n",
      "133/133 [==============================] - 14s 108ms/step - loss: 2.8820 - accuracy: 0.1058 - val_loss: 2.7488 - val_accuracy: 0.1707\n",
      "Epoch 4/15\n",
      "133/133 [==============================] - 15s 114ms/step - loss: 2.4393 - accuracy: 0.2389 - val_loss: 2.3362 - val_accuracy: 0.2680\n",
      "Epoch 5/15\n",
      "133/133 [==============================] - 16s 123ms/step - loss: 2.0192 - accuracy: 0.3531 - val_loss: 2.0325 - val_accuracy: 0.3633\n",
      "Epoch 6/15\n",
      "133/133 [==============================] - 17s 125ms/step - loss: 1.6873 - accuracy: 0.4591 - val_loss: 1.8626 - val_accuracy: 0.4007\n",
      "Epoch 7/15\n",
      "133/133 [==============================] - 15s 114ms/step - loss: 1.4207 - accuracy: 0.5365 - val_loss: 1.6386 - val_accuracy: 0.4860\n",
      "Epoch 8/15\n",
      "133/133 [==============================] - 16s 117ms/step - loss: 1.2529 - accuracy: 0.5986 - val_loss: 1.5359 - val_accuracy: 0.5307\n",
      "Epoch 9/15\n",
      "133/133 [==============================] - 15s 114ms/step - loss: 1.1255 - accuracy: 0.6360 - val_loss: 1.5441 - val_accuracy: 0.5340\n",
      "Epoch 10/15\n",
      "133/133 [==============================] - 18s 132ms/step - loss: 1.0083 - accuracy: 0.6742 - val_loss: 1.4463 - val_accuracy: 0.5560\n",
      "Epoch 11/15\n",
      "133/133 [==============================] - 15s 115ms/step - loss: 0.9241 - accuracy: 0.6982 - val_loss: 1.4065 - val_accuracy: 0.5733\n",
      "Epoch 12/15\n",
      "133/133 [==============================] - 15s 116ms/step - loss: 0.8356 - accuracy: 0.7300 - val_loss: 1.3861 - val_accuracy: 0.5853\n",
      "Epoch 13/15\n",
      "133/133 [==============================] - 15s 116ms/step - loss: 0.7791 - accuracy: 0.7493 - val_loss: 1.3938 - val_accuracy: 0.5807\n",
      "Epoch 14/15\n",
      "133/133 [==============================] - 15s 115ms/step - loss: 0.7165 - accuracy: 0.7733 - val_loss: 1.3978 - val_accuracy: 0.6007\n",
      "Epoch 15/15\n",
      "133/133 [==============================] - 16s 123ms/step - loss: 0.6515 - accuracy: 0.7933 - val_loss: 1.3621 - val_accuracy: 0.6007\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 25, 125, 32)       832       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 12, 62, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 12, 62, 32)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 23808)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                1523776   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 21)                1365      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,525,973\n",
      "Trainable params: 1,525,973\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "133/133 [==============================] - 17s 125ms/step - loss: 3.0532 - accuracy: 0.0513 - val_loss: 3.0322 - val_accuracy: 0.0660\n",
      "Epoch 2/15\n",
      "133/133 [==============================] - 15s 113ms/step - loss: 2.8885 - accuracy: 0.1182 - val_loss: 2.6315 - val_accuracy: 0.1867\n",
      "Epoch 3/15\n",
      "133/133 [==============================] - 15s 109ms/step - loss: 2.1632 - accuracy: 0.3453 - val_loss: 2.0725 - val_accuracy: 0.3667\n",
      "Epoch 4/15\n",
      "133/133 [==============================] - 17s 126ms/step - loss: 1.5736 - accuracy: 0.5215 - val_loss: 1.7624 - val_accuracy: 0.4713\n",
      "Epoch 5/15\n",
      "133/133 [==============================] - 15s 109ms/step - loss: 1.2061 - accuracy: 0.6446 - val_loss: 1.6391 - val_accuracy: 0.5140\n",
      "Epoch 6/15\n",
      "133/133 [==============================] - 16s 120ms/step - loss: 0.9786 - accuracy: 0.7113 - val_loss: 1.5192 - val_accuracy: 0.5520\n",
      "Epoch 7/15\n",
      "133/133 [==============================] - 16s 117ms/step - loss: 0.7787 - accuracy: 0.7757 - val_loss: 1.4890 - val_accuracy: 0.5733\n",
      "Epoch 8/15\n",
      "133/133 [==============================] - 15s 113ms/step - loss: 0.6579 - accuracy: 0.8054 - val_loss: 1.4530 - val_accuracy: 0.5947\n",
      "Epoch 9/15\n",
      "133/133 [==============================] - 16s 120ms/step - loss: 0.5214 - accuracy: 0.8486 - val_loss: 1.3910 - val_accuracy: 0.6240\n",
      "Epoch 10/15\n",
      "133/133 [==============================] - 16s 123ms/step - loss: 0.4400 - accuracy: 0.8784 - val_loss: 1.4299 - val_accuracy: 0.6213\n",
      "Epoch 11/15\n",
      "133/133 [==============================] - 15s 115ms/step - loss: 0.3623 - accuracy: 0.9021 - val_loss: 1.3923 - val_accuracy: 0.6433\n",
      "Epoch 12/15\n",
      "133/133 [==============================] - 16s 117ms/step - loss: 0.3062 - accuracy: 0.9160 - val_loss: 1.4566 - val_accuracy: 0.6340\n",
      "Epoch 13/15\n",
      "133/133 [==============================] - 16s 121ms/step - loss: 0.2561 - accuracy: 0.9335 - val_loss: 1.4220 - val_accuracy: 0.6527\n",
      "Epoch 14/15\n",
      "133/133 [==============================] - 16s 120ms/step - loss: 0.2148 - accuracy: 0.9479 - val_loss: 1.4493 - val_accuracy: 0.6433\n",
      "Epoch 15/15\n",
      "133/133 [==============================] - 16s 119ms/step - loss: 0.1783 - accuracy: 0.9568 - val_loss: 1.5255 - val_accuracy: 0.6593\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 25, 125, 32)       832       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 12, 62, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 12, 62, 32)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 23808)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                1523776   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 21)                1365      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,525,973\n",
      "Trainable params: 1,525,973\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "133/133 [==============================] - 16s 116ms/step - loss: 3.0524 - accuracy: 0.0499 - val_loss: 3.0336 - val_accuracy: 0.0627\n",
      "Epoch 2/15\n",
      "133/133 [==============================] - 16s 121ms/step - loss: 2.7655 - accuracy: 0.1581 - val_loss: 2.3345 - val_accuracy: 0.3240\n",
      "Epoch 3/15\n",
      "133/133 [==============================] - 16s 119ms/step - loss: 1.8331 - accuracy: 0.4581 - val_loss: 1.7856 - val_accuracy: 0.4620\n",
      "Epoch 4/15\n",
      "133/133 [==============================] - 16s 123ms/step - loss: 1.2599 - accuracy: 0.6360 - val_loss: 1.5035 - val_accuracy: 0.5527\n",
      "Epoch 5/15\n",
      "133/133 [==============================] - 15s 113ms/step - loss: 0.9273 - accuracy: 0.7323 - val_loss: 1.3311 - val_accuracy: 0.6060\n",
      "Epoch 6/15\n",
      "133/133 [==============================] - 15s 113ms/step - loss: 0.7157 - accuracy: 0.7867 - val_loss: 1.2440 - val_accuracy: 0.6507\n",
      "Epoch 7/15\n",
      "133/133 [==============================] - 16s 122ms/step - loss: 0.5322 - accuracy: 0.8530 - val_loss: 1.2380 - val_accuracy: 0.6480\n",
      "Epoch 8/15\n",
      "133/133 [==============================] - 16s 119ms/step - loss: 0.4117 - accuracy: 0.8879 - val_loss: 1.2322 - val_accuracy: 0.6533\n",
      "Epoch 9/15\n",
      "133/133 [==============================] - 15s 115ms/step - loss: 0.3200 - accuracy: 0.9125 - val_loss: 1.2084 - val_accuracy: 0.6727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15\n",
      "133/133 [==============================] - 14s 105ms/step - loss: 0.2585 - accuracy: 0.9368 - val_loss: 1.2121 - val_accuracy: 0.6860\n",
      "Epoch 11/15\n",
      "133/133 [==============================] - 14s 108ms/step - loss: 0.2025 - accuracy: 0.9525 - val_loss: 1.2261 - val_accuracy: 0.6773\n",
      "Epoch 12/15\n",
      "133/133 [==============================] - 16s 121ms/step - loss: 0.1608 - accuracy: 0.9635 - val_loss: 1.3337 - val_accuracy: 0.6687\n",
      "Epoch 13/15\n",
      "133/133 [==============================] - 15s 115ms/step - loss: 0.1378 - accuracy: 0.9677 - val_loss: 1.2709 - val_accuracy: 0.6947\n",
      "Epoch 14/15\n",
      "133/133 [==============================] - 15s 114ms/step - loss: 0.1073 - accuracy: 0.9776 - val_loss: 1.2800 - val_accuracy: 0.6967\n",
      "Epoch 15/15\n",
      "133/133 [==============================] - 16s 120ms/step - loss: 0.0876 - accuracy: 0.9842 - val_loss: 1.3068 - val_accuracy: 0.6867\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 25, 125, 32)       832       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 12, 62, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 12, 62, 32)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 23808)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                1523776   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 21)                1365      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,525,973\n",
      "Trainable params: 1,525,973\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "133/133 [==============================] - 16s 117ms/step - loss: 3.0517 - accuracy: 0.0547 - val_loss: 3.0299 - val_accuracy: 0.0473\n",
      "Epoch 2/15\n",
      "133/133 [==============================] - 15s 113ms/step - loss: 2.9569 - accuracy: 0.0799 - val_loss: 2.8170 - val_accuracy: 0.1140\n",
      "Epoch 3/15\n",
      "133/133 [==============================] - 16s 119ms/step - loss: 2.5496 - accuracy: 0.1897 - val_loss: 2.4259 - val_accuracy: 0.2320\n",
      "Epoch 4/15\n",
      "133/133 [==============================] - 14s 106ms/step - loss: 2.1646 - accuracy: 0.2887 - val_loss: 2.2163 - val_accuracy: 0.2687\n",
      "Epoch 5/15\n",
      "133/133 [==============================] - 15s 114ms/step - loss: 1.9273 - accuracy: 0.3517 - val_loss: 2.0766 - val_accuracy: 0.3207\n",
      "Epoch 6/15\n",
      "133/133 [==============================] - 16s 120ms/step - loss: 1.7610 - accuracy: 0.4089 - val_loss: 1.9870 - val_accuracy: 0.3447\n",
      "Epoch 7/15\n",
      "133/133 [==============================] - 15s 113ms/step - loss: 1.6073 - accuracy: 0.4556 - val_loss: 1.8598 - val_accuracy: 0.3747\n",
      "Epoch 8/15\n",
      "133/133 [==============================] - 15s 114ms/step - loss: 1.4945 - accuracy: 0.4952 - val_loss: 1.7415 - val_accuracy: 0.4280\n",
      "Epoch 9/15\n",
      "133/133 [==============================] - 16s 119ms/step - loss: 1.3913 - accuracy: 0.5239 - val_loss: 1.7107 - val_accuracy: 0.4360\n",
      "Epoch 10/15\n",
      "133/133 [==============================] - 16s 120ms/step - loss: 1.3009 - accuracy: 0.5542 - val_loss: 1.6867 - val_accuracy: 0.4453\n",
      "Epoch 11/15\n",
      "133/133 [==============================] - 16s 119ms/step - loss: 1.2146 - accuracy: 0.5876 - val_loss: 1.6115 - val_accuracy: 0.4733\n",
      "Epoch 12/15\n",
      "133/133 [==============================] - 16s 118ms/step - loss: 1.1393 - accuracy: 0.6135 - val_loss: 1.5883 - val_accuracy: 0.4820\n",
      "Epoch 13/15\n",
      "133/133 [==============================] - 15s 110ms/step - loss: 1.0667 - accuracy: 0.6393 - val_loss: 1.4478 - val_accuracy: 0.5487\n",
      "Epoch 14/15\n",
      "133/133 [==============================] - 16s 117ms/step - loss: 0.9974 - accuracy: 0.6647 - val_loss: 1.3947 - val_accuracy: 0.5693\n",
      "Epoch 15/15\n",
      "133/133 [==============================] - 15s 115ms/step - loss: 0.9062 - accuracy: 0.7003 - val_loss: 1.3857 - val_accuracy: 0.5933\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "for i in range(6):\n",
    "    models[i] = train_model(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d23e6579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 6)\n",
      "47/47 [==============================] - 2s 37ms/step\n",
      "47/47 [==============================] - 2s 37ms/step\n",
      "47/47 [==============================] - 2s 38ms/step\n",
      "47/47 [==============================] - 2s 36ms/step\n",
      "47/47 [==============================] - 1s 12ms/step\n",
      "47/47 [==============================] - 1s 30ms/step\n"
     ]
    }
   ],
   "source": [
    "results = np.zeros((n_test,6), dtype=object)\n",
    "for i in range(6):\n",
    "    y_pred = pred_classes(models[i].predict(X_test))\n",
    "    results[:,i] = encoder.inverse_transform(y_pred).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9cc17ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['6', '6', 'G', 'C', 'K', 'T'],\n",
       "       ['6', '6', 'G', '6', 'X', 'T'],\n",
       "       ['6', '6', 'G', 'C', 'C', 'T'],\n",
       "       ...,\n",
       "       ['6', '6', 'G', 'N', 'C', '2'],\n",
       "       ['6', '6', 'G', 'N', 'C', '2'],\n",
       "       ['6', '6', 'G', 'N', 'C', 'T']], dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8ef53a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False],\n",
       "       ...,\n",
       "       [False, False,  True, False,  True, False],\n",
       "       [False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_test == results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bf538c41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 25, 125, 32)       832       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 12, 62, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 12, 62, 32)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 23808)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                1523776   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 21)                1365      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,525,973\n",
      "Trainable params: 1,525,973\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "133/133 [==============================] - 16s 117ms/step - loss: 3.0506 - accuracy: 0.0662 - val_loss: 2.9972 - val_accuracy: 0.0847\n",
      "Epoch 2/15\n",
      "133/133 [==============================] - 16s 117ms/step - loss: 2.7245 - accuracy: 0.1944 - val_loss: 2.3966 - val_accuracy: 0.2747\n",
      "Epoch 3/15\n",
      "133/133 [==============================] - 15s 112ms/step - loss: 1.9154 - accuracy: 0.4138 - val_loss: 1.7413 - val_accuracy: 0.4600\n",
      "Epoch 4/15\n",
      "133/133 [==============================] - 15s 114ms/step - loss: 1.3337 - accuracy: 0.5912 - val_loss: 1.3594 - val_accuracy: 0.5773\n",
      "Epoch 5/15\n",
      "133/133 [==============================] - 16s 121ms/step - loss: 0.9644 - accuracy: 0.7071 - val_loss: 1.1321 - val_accuracy: 0.6613\n",
      "Epoch 6/15\n",
      "133/133 [==============================] - 15s 114ms/step - loss: 0.7547 - accuracy: 0.7711 - val_loss: 1.0196 - val_accuracy: 0.6940\n",
      "Epoch 7/15\n",
      "133/133 [==============================] - 15s 110ms/step - loss: 0.6021 - accuracy: 0.8277 - val_loss: 0.9574 - val_accuracy: 0.7060\n",
      "Epoch 8/15\n",
      "133/133 [==============================] - 16s 119ms/step - loss: 0.4953 - accuracy: 0.8514 - val_loss: 0.8554 - val_accuracy: 0.7393\n",
      "Epoch 9/15\n",
      "133/133 [==============================] - 15s 115ms/step - loss: 0.4135 - accuracy: 0.8782 - val_loss: 0.8414 - val_accuracy: 0.7460\n",
      "Epoch 10/15\n",
      "133/133 [==============================] - 16s 122ms/step - loss: 0.3557 - accuracy: 0.8950 - val_loss: 0.9439 - val_accuracy: 0.7073\n",
      "Epoch 11/15\n",
      "133/133 [==============================] - 15s 113ms/step - loss: 0.3083 - accuracy: 0.9104 - val_loss: 0.8303 - val_accuracy: 0.7600\n",
      "Epoch 12/15\n",
      "133/133 [==============================] - 16s 119ms/step - loss: 0.2603 - accuracy: 0.9274 - val_loss: 0.8005 - val_accuracy: 0.7687\n",
      "Epoch 13/15\n",
      "133/133 [==============================] - 16s 122ms/step - loss: 0.2298 - accuracy: 0.9355 - val_loss: 0.8307 - val_accuracy: 0.7520\n",
      "Epoch 14/15\n",
      "133/133 [==============================] - 15s 113ms/step - loss: 0.2031 - accuracy: 0.9449 - val_loss: 0.8331 - val_accuracy: 0.7600\n",
      "Epoch 15/15\n",
      "133/133 [==============================] - 17s 124ms/step - loss: 0.1829 - accuracy: 0.9498 - val_loss: 0.7832 - val_accuracy: 0.7767\n"
     ]
    }
   ],
   "source": [
    "model_a = train_model(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "01b614db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 2s 44ms/step\n",
      "47/47 [==============================] - 2s 43ms/step\n",
      "47/47 [==============================] - 1s 28ms/step\n",
      "47/47 [==============================] - 2s 39ms/step\n",
      "47/47 [==============================] - 1s 23ms/step\n",
      "47/47 [==============================] - 1s 30ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['A', '6', '6', 'X', 'A', 'H'],\n",
       "       ['P', 'D', 'B', 'G', 'C', 'Z'],\n",
       "       ['M', 'S', 'A', 'A', 'R', 'E'],\n",
       "       ...,\n",
       "       ['G', 'V', 'C', 'P', 'C', 'U'],\n",
       "       ['E', '6', 'B', 'X', 'V', 'B'],\n",
       "       ['R', '6', 'B', 'R', 'M', 'P']], dtype=object)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = np.zeros((n_test,6), dtype=object)\n",
    "for i in range(6):\n",
    "    y_pred = pred_classes(models[i].predict(X_test))\n",
    "    results[:,i] = encoder.inverse_transform(y_pred).flatten()\n",
    "    \n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "957310e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5969"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(results == labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d4ecf6ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=250x50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=250x50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=250x50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    show_im(X_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "46dd3a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 25, 125, 32)       832       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 63, 32)        25632     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 6, 31, 32)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 6, 31, 32)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 5952)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                380992    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 21)                1365      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 408,821\n",
      "Trainable params: 408,821\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "133/133 [==============================] - 18s 128ms/step - loss: 3.0396 - accuracy: 0.0589 - val_loss: 2.9730 - val_accuracy: 0.1287\n",
      "Epoch 2/15\n",
      "133/133 [==============================] - 18s 135ms/step - loss: 2.1047 - accuracy: 0.3496 - val_loss: 1.4712 - val_accuracy: 0.5093\n",
      "Epoch 3/15\n",
      "133/133 [==============================] - 19s 144ms/step - loss: 0.9913 - accuracy: 0.6851 - val_loss: 0.8893 - val_accuracy: 0.7167\n",
      "Epoch 4/15\n",
      "133/133 [==============================] - 19s 141ms/step - loss: 0.6075 - accuracy: 0.8052 - val_loss: 0.6614 - val_accuracy: 0.7773\n",
      "Epoch 5/15\n",
      "133/133 [==============================] - 19s 140ms/step - loss: 0.3963 - accuracy: 0.8717 - val_loss: 0.5637 - val_accuracy: 0.8167\n",
      "Epoch 6/15\n",
      "133/133 [==============================] - 18s 135ms/step - loss: 0.2993 - accuracy: 0.9028 - val_loss: 0.5388 - val_accuracy: 0.8280\n",
      "Epoch 7/15\n",
      "133/133 [==============================] - 17s 125ms/step - loss: 0.2185 - accuracy: 0.9301 - val_loss: 0.5327 - val_accuracy: 0.8353\n",
      "Epoch 8/15\n",
      "133/133 [==============================] - 18s 132ms/step - loss: 0.1691 - accuracy: 0.9481 - val_loss: 0.5353 - val_accuracy: 0.8367\n",
      "Epoch 9/15\n",
      "133/133 [==============================] - 18s 134ms/step - loss: 0.1544 - accuracy: 0.9513 - val_loss: 0.5767 - val_accuracy: 0.8333\n",
      "Epoch 10/15\n",
      "133/133 [==============================] - 19s 146ms/step - loss: 0.1269 - accuracy: 0.9624 - val_loss: 0.5521 - val_accuracy: 0.8567\n",
      "Epoch 11/15\n",
      "133/133 [==============================] - 19s 139ms/step - loss: 0.1036 - accuracy: 0.9651 - val_loss: 0.5410 - val_accuracy: 0.8460\n",
      "Epoch 12/15\n",
      "133/133 [==============================] - 18s 134ms/step - loss: 0.0968 - accuracy: 0.9693 - val_loss: 0.5270 - val_accuracy: 0.8467\n",
      "Epoch 13/15\n",
      "133/133 [==============================] - 19s 143ms/step - loss: 0.0904 - accuracy: 0.9701 - val_loss: 0.5361 - val_accuracy: 0.8547\n",
      "Epoch 14/15\n",
      "133/133 [==============================] - 20s 152ms/step - loss: 0.0825 - accuracy: 0.9726 - val_loss: 0.5822 - val_accuracy: 0.8407\n",
      "Epoch 15/15\n",
      "133/133 [==============================] - 18s 132ms/step - loss: 0.0671 - accuracy: 0.9794 - val_loss: 0.6238 - val_accuracy: 0.8547\n"
     ]
    }
   ],
   "source": [
    "model = train_model(X_train, X_test, y_train[0], y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c25be6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 2s 44ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7211.0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_0 = pred_classes(model.predict(X_test))\n",
    "results_0 = encoder.inverse_transform(results_0).flatten()\n",
    "np.sum(results_0 == labels_test[:,0]) / n_test * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8fdc9372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>S</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>B</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>E</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>N</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>218 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Predicted True\n",
       "0           K    X\n",
       "1           C    6\n",
       "2           M    N\n",
       "3           B    E\n",
       "4           M    H\n",
       "..        ...  ...\n",
       "213         M    H\n",
       "214         S    6\n",
       "215         B    E\n",
       "216         E    F\n",
       "217         N    X\n",
       "\n",
       "[218 rows x 2 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = results_0 != labels_test[:,0]\n",
    "pd.DataFrame([results_0[idx], labels_test[idx, 0]], index=['Predicted', 'True']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b427d1c",
   "metadata": {},
   "source": [
    "### Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e228f5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 25, 125, 32)       832       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 63, 32)        25632     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 6, 31, 32)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 6, 31, 32)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 5952)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               3047936   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 21)                10773     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,085,173\n",
      "Trainable params: 3,085,173\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "133/133 [==============================] - 16s 116ms/step - loss: 2.9075 - accuracy: 0.1114 - val_loss: 2.2217 - val_accuracy: 0.3180\n",
      "Epoch 2/15\n",
      "133/133 [==============================] - 16s 118ms/step - loss: 1.6566 - accuracy: 0.4777 - val_loss: 1.1153 - val_accuracy: 0.6547\n",
      "Epoch 3/15\n",
      "133/133 [==============================] - 16s 119ms/step - loss: 0.9222 - accuracy: 0.7057 - val_loss: 0.7922 - val_accuracy: 0.7460\n",
      "Epoch 4/15\n",
      "133/133 [==============================] - 16s 119ms/step - loss: 0.5915 - accuracy: 0.8092 - val_loss: 0.6495 - val_accuracy: 0.7907\n",
      "Epoch 5/15\n",
      "133/133 [==============================] - 15s 110ms/step - loss: 0.4157 - accuracy: 0.8639 - val_loss: 0.5851 - val_accuracy: 0.8140\n",
      "Epoch 6/15\n",
      "133/133 [==============================] - 16s 119ms/step - loss: 0.3048 - accuracy: 0.8998 - val_loss: 0.5536 - val_accuracy: 0.8220\n",
      "Epoch 7/15\n",
      "133/133 [==============================] - 16s 118ms/step - loss: 0.2274 - accuracy: 0.9237 - val_loss: 0.5656 - val_accuracy: 0.8273\n",
      "Epoch 8/15\n",
      "133/133 [==============================] - 18s 132ms/step - loss: 0.1963 - accuracy: 0.9377 - val_loss: 0.5133 - val_accuracy: 0.8413\n",
      "Epoch 9/15\n",
      "133/133 [==============================] - 17s 125ms/step - loss: 0.1425 - accuracy: 0.9548 - val_loss: 0.5214 - val_accuracy: 0.8440\n",
      "Epoch 10/15\n",
      "133/133 [==============================] - 18s 138ms/step - loss: 0.1269 - accuracy: 0.9569 - val_loss: 0.4660 - val_accuracy: 0.8527\n",
      "Epoch 11/15\n",
      "133/133 [==============================] - 17s 130ms/step - loss: 0.1049 - accuracy: 0.9666 - val_loss: 0.4989 - val_accuracy: 0.8560\n",
      "Epoch 12/15\n",
      "133/133 [==============================] - 14s 109ms/step - loss: 0.0976 - accuracy: 0.9692 - val_loss: 0.4981 - val_accuracy: 0.8513\n",
      "Epoch 13/15\n",
      "133/133 [==============================] - 14s 108ms/step - loss: 0.0807 - accuracy: 0.9752 - val_loss: 0.4990 - val_accuracy: 0.8573\n",
      "Epoch 14/15\n",
      "133/133 [==============================] - 15s 113ms/step - loss: 0.0798 - accuracy: 0.9744 - val_loss: 0.5354 - val_accuracy: 0.8460\n",
      "Epoch 15/15\n",
      "133/133 [==============================] - 16s 118ms/step - loss: 0.0769 - accuracy: 0.9737 - val_loss: 0.6098 - val_accuracy: 0.8347\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0525a7e710>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "char = 0\n",
    "filters = 32\n",
    "shape = 5\n",
    "stride = 2\n",
    "pad ='same'\n",
    "act = 'relu'\n",
    "n_classes = y_train[char].shape[1]\n",
    "\n",
    "# Layers to be frozen\n",
    "feature_layers = [\n",
    "    Conv2D(filters, shape, strides=stride, padding=pad, activation=act,\n",
    "           input_shape=X_train.shape[1:]),\n",
    "    Conv2D(filters, shape, strides=stride, padding=pad, activation=act),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    Dropout(0.25),\n",
    "    Flatten()\n",
    "]\n",
    "\n",
    "# Classification layers\n",
    "class_layers = [\n",
    "    Dense(512, activation=act),\n",
    "    Dense(n_classes, activation='softmax')\n",
    "]\n",
    "\n",
    "\n",
    "# Simple CNN\n",
    "model = Sequential(feature_layers + class_layers)\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train[char],\n",
    "              batch_size=64,\n",
    "              epochs=15,\n",
    "              validation_data=(X_test, y_test[char]),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1e0e6fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 25, 125, 32)       832       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 63, 32)        25632     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 6, 31, 32)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 6, 31, 32)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 5952)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               761984    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 21)                2709      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 791,157\n",
      "Trainable params: 764,693\n",
      "Non-trainable params: 26,464\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Freeze the feature layers and train for character 2\n",
    "char = 1\n",
    "for l in feature_layers:\n",
    "    l.trainable = False\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3b86af6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "133/133 [==============================] - 7s 50ms/step - loss: 4.4914 - accuracy: 0.0692 - val_loss: 2.9139 - val_accuracy: 0.0953\n",
      "Epoch 2/15\n",
      "133/133 [==============================] - 5s 36ms/step - loss: 2.7195 - accuracy: 0.1668 - val_loss: 2.3994 - val_accuracy: 0.2600\n",
      "Epoch 3/15\n",
      "133/133 [==============================] - 6s 42ms/step - loss: 2.1122 - accuracy: 0.3418 - val_loss: 1.7798 - val_accuracy: 0.4373\n",
      "Epoch 4/15\n",
      "133/133 [==============================] - 6s 46ms/step - loss: 1.6456 - accuracy: 0.4864 - val_loss: 1.4658 - val_accuracy: 0.5540\n",
      "Epoch 5/15\n",
      "133/133 [==============================] - 6s 46ms/step - loss: 1.3958 - accuracy: 0.5602 - val_loss: 1.2888 - val_accuracy: 0.6013\n",
      "Epoch 6/15\n",
      "133/133 [==============================] - 6s 46ms/step - loss: 1.2235 - accuracy: 0.6143 - val_loss: 1.1705 - val_accuracy: 0.6467\n",
      "Epoch 7/15\n",
      "133/133 [==============================] - 6s 44ms/step - loss: 1.1010 - accuracy: 0.6532 - val_loss: 1.0419 - val_accuracy: 0.6833\n",
      "Epoch 8/15\n",
      "133/133 [==============================] - 6s 43ms/step - loss: 0.9765 - accuracy: 0.6925 - val_loss: 0.9578 - val_accuracy: 0.7033\n",
      "Epoch 9/15\n",
      "133/133 [==============================] - 6s 43ms/step - loss: 0.8750 - accuracy: 0.7293 - val_loss: 0.8836 - val_accuracy: 0.7253\n",
      "Epoch 10/15\n",
      "133/133 [==============================] - 4s 30ms/step - loss: 0.7995 - accuracy: 0.7484 - val_loss: 0.8514 - val_accuracy: 0.7300\n",
      "Epoch 11/15\n",
      "133/133 [==============================] - 6s 42ms/step - loss: 0.7379 - accuracy: 0.7641 - val_loss: 0.7988 - val_accuracy: 0.7567\n",
      "Epoch 12/15\n",
      "133/133 [==============================] - 6s 47ms/step - loss: 0.6538 - accuracy: 0.7884 - val_loss: 0.7721 - val_accuracy: 0.7520\n",
      "Epoch 13/15\n",
      "133/133 [==============================] - 5s 37ms/step - loss: 0.6020 - accuracy: 0.8100 - val_loss: 0.7268 - val_accuracy: 0.7667\n",
      "Epoch 14/15\n",
      "133/133 [==============================] - 5s 38ms/step - loss: 0.5642 - accuracy: 0.8228 - val_loss: 0.7239 - val_accuracy: 0.7673\n",
      "Epoch 15/15\n",
      "133/133 [==============================] - 5s 36ms/step - loss: 0.5297 - accuracy: 0.8338 - val_loss: 0.7075 - val_accuracy: 0.7827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f05258b8750>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train[char],\n",
    "              batch_size=64,\n",
    "              epochs=15,\n",
    "              validation_data=(X_test, y_test[char]),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "391c99e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "133/133 [==============================] - 17s 127ms/step - loss: 3.7205 - accuracy: 0.0820 - val_loss: 2.7695 - val_accuracy: 0.1927\n",
      "Epoch 2/15\n",
      "133/133 [==============================] - 15s 114ms/step - loss: 2.0433 - accuracy: 0.3720 - val_loss: 1.1976 - val_accuracy: 0.6293\n",
      "Epoch 3/15\n",
      "133/133 [==============================] - 16s 119ms/step - loss: 0.8216 - accuracy: 0.7421 - val_loss: 0.6251 - val_accuracy: 0.8073\n",
      "Epoch 4/15\n",
      "133/133 [==============================] - 16s 119ms/step - loss: 0.3851 - accuracy: 0.8824 - val_loss: 0.4653 - val_accuracy: 0.8480\n",
      "Epoch 5/15\n",
      "133/133 [==============================] - 14s 104ms/step - loss: 0.2252 - accuracy: 0.9295 - val_loss: 0.4192 - val_accuracy: 0.8733\n",
      "Epoch 6/15\n",
      "133/133 [==============================] - 17s 126ms/step - loss: 0.1483 - accuracy: 0.9540 - val_loss: 0.4270 - val_accuracy: 0.8667\n",
      "Epoch 7/15\n",
      "133/133 [==============================] - 15s 116ms/step - loss: 0.1187 - accuracy: 0.9654 - val_loss: 0.4136 - val_accuracy: 0.8760\n",
      "Epoch 8/15\n",
      "133/133 [==============================] - 15s 113ms/step - loss: 0.0766 - accuracy: 0.9781 - val_loss: 0.4266 - val_accuracy: 0.8767\n",
      "Epoch 9/15\n",
      "133/133 [==============================] - 15s 115ms/step - loss: 0.0763 - accuracy: 0.9776 - val_loss: 0.4352 - val_accuracy: 0.8780\n",
      "Epoch 10/15\n",
      "133/133 [==============================] - 16s 117ms/step - loss: 0.0626 - accuracy: 0.9816 - val_loss: 0.4047 - val_accuracy: 0.8787\n",
      "Epoch 11/15\n",
      "133/133 [==============================] - 15s 115ms/step - loss: 0.0566 - accuracy: 0.9820 - val_loss: 0.4395 - val_accuracy: 0.8760\n",
      "Epoch 12/15\n",
      "133/133 [==============================] - 15s 116ms/step - loss: 0.0573 - accuracy: 0.9834 - val_loss: 0.4155 - val_accuracy: 0.8853\n",
      "Epoch 13/15\n",
      "133/133 [==============================] - 14s 107ms/step - loss: 0.0448 - accuracy: 0.9865 - val_loss: 0.4709 - val_accuracy: 0.8660\n",
      "Epoch 14/15\n",
      "133/133 [==============================] - 15s 113ms/step - loss: 0.0466 - accuracy: 0.9856 - val_loss: 0.4190 - val_accuracy: 0.8860\n",
      "Epoch 15/15\n",
      "133/133 [==============================] - 15s 115ms/step - loss: 0.0381 - accuracy: 0.9887 - val_loss: 0.4119 - val_accuracy: 0.8807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f05257a6c10>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Character 6\n",
    "char = 5\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train[char],\n",
    "              batch_size=64,\n",
    "              epochs=15,\n",
    "              validation_data=(X_test, y_test[char]),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ac6b4b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character 2\n",
      "Epoch 1/15\n",
      "133/133 [==============================] - 16s 117ms/step - loss: 0.0558 - accuracy: 0.9818 - val_loss: 0.4856 - val_accuracy: 0.8767\n",
      "Epoch 2/15\n",
      "133/133 [==============================] - 15s 109ms/step - loss: 0.0486 - accuracy: 0.9862 - val_loss: 0.4863 - val_accuracy: 0.8773\n",
      "Epoch 3/15\n",
      "133/133 [==============================] - 15s 114ms/step - loss: 0.0489 - accuracy: 0.9858 - val_loss: 0.4882 - val_accuracy: 0.8733\n",
      "Epoch 4/15\n",
      "133/133 [==============================] - 15s 112ms/step - loss: 0.0457 - accuracy: 0.9860 - val_loss: 0.4888 - val_accuracy: 0.8713\n",
      "Epoch 5/15\n",
      "133/133 [==============================] - 14s 101ms/step - loss: 0.0362 - accuracy: 0.9892 - val_loss: 0.5164 - val_accuracy: 0.8733\n",
      "Epoch 6/15\n",
      "133/133 [==============================] - 14s 102ms/step - loss: 0.0398 - accuracy: 0.9894 - val_loss: 0.4200 - val_accuracy: 0.8860\n",
      "Epoch 7/15\n",
      "133/133 [==============================] - 16s 123ms/step - loss: 0.0288 - accuracy: 0.9909 - val_loss: 0.4536 - val_accuracy: 0.8960\n",
      "Epoch 8/15\n",
      "133/133 [==============================] - 16s 117ms/step - loss: 0.0295 - accuracy: 0.9906 - val_loss: 0.5230 - val_accuracy: 0.8793\n",
      "Epoch 9/15\n",
      "133/133 [==============================] - 16s 117ms/step - loss: 0.0304 - accuracy: 0.9898 - val_loss: 0.5137 - val_accuracy: 0.8727\n",
      "Epoch 10/15\n",
      "133/133 [==============================] - 16s 121ms/step - loss: 0.0321 - accuracy: 0.9904 - val_loss: 0.6059 - val_accuracy: 0.8560\n",
      "Epoch 11/15\n",
      "133/133 [==============================] - 15s 113ms/step - loss: 0.0331 - accuracy: 0.9889 - val_loss: 0.4574 - val_accuracy: 0.8920\n",
      "Epoch 12/15\n",
      "133/133 [==============================] - 14s 108ms/step - loss: 0.0216 - accuracy: 0.9933 - val_loss: 0.5473 - val_accuracy: 0.8753\n",
      "Epoch 13/15\n",
      "133/133 [==============================] - 15s 109ms/step - loss: 0.0293 - accuracy: 0.9921 - val_loss: 0.5667 - val_accuracy: 0.8793\n",
      "Epoch 14/15\n",
      "133/133 [==============================] - 16s 120ms/step - loss: 0.0266 - accuracy: 0.9906 - val_loss: 0.4712 - val_accuracy: 0.8873\n",
      "Epoch 15/15\n",
      "133/133 [==============================] - 16s 122ms/step - loss: 0.0371 - accuracy: 0.9888 - val_loss: 0.5292 - val_accuracy: 0.8767\n",
      "Character 3\n",
      "Epoch 1/15\n",
      "133/133 [==============================] - 15s 110ms/step - loss: 0.0312 - accuracy: 0.9899 - val_loss: 0.6416 - val_accuracy: 0.8560\n",
      "Epoch 2/15\n",
      "133/133 [==============================] - 15s 114ms/step - loss: 0.0316 - accuracy: 0.9911 - val_loss: 0.5488 - val_accuracy: 0.8740\n",
      "Epoch 3/15\n",
      "133/133 [==============================] - 14s 109ms/step - loss: 0.0239 - accuracy: 0.9928 - val_loss: 0.5489 - val_accuracy: 0.8833\n",
      "Epoch 4/15\n",
      "133/133 [==============================] - 15s 115ms/step - loss: 0.0236 - accuracy: 0.9927 - val_loss: 0.5522 - val_accuracy: 0.8813\n",
      "Epoch 5/15\n",
      "133/133 [==============================] - 15s 115ms/step - loss: 0.0298 - accuracy: 0.9908 - val_loss: 0.5932 - val_accuracy: 0.8787\n",
      "Epoch 6/15\n",
      "133/133 [==============================] - 14s 108ms/step - loss: 0.0241 - accuracy: 0.9929 - val_loss: 0.5468 - val_accuracy: 0.8820\n",
      "Epoch 7/15\n",
      "133/133 [==============================] - 15s 109ms/step - loss: 0.0221 - accuracy: 0.9933 - val_loss: 0.5068 - val_accuracy: 0.8880\n",
      "Epoch 8/15\n",
      "133/133 [==============================] - 15s 114ms/step - loss: 0.0308 - accuracy: 0.9908 - val_loss: 0.5686 - val_accuracy: 0.8800\n",
      "Epoch 9/15\n",
      "133/133 [==============================] - 15s 112ms/step - loss: 0.0217 - accuracy: 0.9927 - val_loss: 0.5208 - val_accuracy: 0.8933\n",
      "Epoch 10/15\n",
      "133/133 [==============================] - 14s 109ms/step - loss: 0.0235 - accuracy: 0.9929 - val_loss: 0.5549 - val_accuracy: 0.8927\n",
      "Epoch 11/15\n",
      "133/133 [==============================] - 15s 116ms/step - loss: 0.0193 - accuracy: 0.9929 - val_loss: 0.5219 - val_accuracy: 0.8973\n",
      "Epoch 12/15\n",
      "133/133 [==============================] - 16s 121ms/step - loss: 0.0181 - accuracy: 0.9946 - val_loss: 0.6533 - val_accuracy: 0.8753\n",
      "Epoch 13/15\n",
      "133/133 [==============================] - 16s 122ms/step - loss: 0.0224 - accuracy: 0.9927 - val_loss: 0.5237 - val_accuracy: 0.8873\n",
      "Epoch 14/15\n",
      "133/133 [==============================] - 15s 109ms/step - loss: 0.0232 - accuracy: 0.9925 - val_loss: 0.5032 - val_accuracy: 0.8827\n",
      "Epoch 15/15\n",
      "133/133 [==============================] - 14s 109ms/step - loss: 0.0191 - accuracy: 0.9946 - val_loss: 0.4740 - val_accuracy: 0.8973\n",
      "Character 4\n",
      "Epoch 1/15\n",
      "133/133 [==============================] - 17s 122ms/step - loss: 0.0214 - accuracy: 0.9935 - val_loss: 0.5591 - val_accuracy: 0.8893\n",
      "Epoch 2/15\n",
      "133/133 [==============================] - 15s 116ms/step - loss: 0.0202 - accuracy: 0.9940 - val_loss: 0.7184 - val_accuracy: 0.8713\n",
      "Epoch 3/15\n",
      "133/133 [==============================] - 15s 116ms/step - loss: 0.0231 - accuracy: 0.9926 - val_loss: 0.5114 - val_accuracy: 0.8913\n",
      "Epoch 4/15\n",
      "133/133 [==============================] - 16s 118ms/step - loss: 0.0183 - accuracy: 0.9952 - val_loss: 0.5969 - val_accuracy: 0.8767\n",
      "Epoch 5/15\n",
      "133/133 [==============================] - 15s 114ms/step - loss: 0.0146 - accuracy: 0.9953 - val_loss: 0.4960 - val_accuracy: 0.8960\n",
      "Epoch 6/15\n",
      "133/133 [==============================] - 17s 125ms/step - loss: 0.0141 - accuracy: 0.9964 - val_loss: 0.5854 - val_accuracy: 0.8900\n",
      "Epoch 7/15\n",
      "133/133 [==============================] - 17s 128ms/step - loss: 0.0224 - accuracy: 0.9925 - val_loss: 0.6619 - val_accuracy: 0.8720\n",
      "Epoch 8/15\n",
      "133/133 [==============================] - 15s 112ms/step - loss: 0.0227 - accuracy: 0.9935 - val_loss: 0.5869 - val_accuracy: 0.8793\n",
      "Epoch 9/15\n",
      "133/133 [==============================] - 14s 108ms/step - loss: 0.0130 - accuracy: 0.9955 - val_loss: 0.6064 - val_accuracy: 0.8760\n",
      "Epoch 10/15\n",
      "133/133 [==============================] - 14s 104ms/step - loss: 0.0108 - accuracy: 0.9967 - val_loss: 0.5141 - val_accuracy: 0.8907\n",
      "Epoch 11/15\n",
      "133/133 [==============================] - 16s 118ms/step - loss: 0.0196 - accuracy: 0.9946 - val_loss: 0.6662 - val_accuracy: 0.8787\n",
      "Epoch 12/15\n",
      "133/133 [==============================] - 16s 118ms/step - loss: 0.0150 - accuracy: 0.9949 - val_loss: 0.5918 - val_accuracy: 0.8847\n",
      "Epoch 13/15\n",
      "133/133 [==============================] - 15s 116ms/step - loss: 0.0196 - accuracy: 0.9947 - val_loss: 0.5794 - val_accuracy: 0.8880\n",
      "Epoch 14/15\n",
      "133/133 [==============================] - 13s 101ms/step - loss: 0.0125 - accuracy: 0.9960 - val_loss: 0.4955 - val_accuracy: 0.8953\n",
      "Epoch 15/15\n",
      "133/133 [==============================] - 14s 105ms/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.5744 - val_accuracy: 0.8787\n"
     ]
    }
   ],
   "source": [
    "for i in range(2,5):\n",
    "    print(f\"Character {i}\")\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train[char],\n",
    "                  batch_size=64,\n",
    "                  epochs=15,\n",
    "                  validation_data=(X_test, y_test[char]),\n",
    "                  shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7ab9ac08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all models\n",
    "def train_model(X_train, X_test, y_train, y_test):\n",
    "    # Clear the current model\n",
    "    keras.backend.clear_session()\n",
    "    \n",
    "    # Store test results\n",
    "    results = np.zeros((y_test[0].shape[0], 6), dtype=object)\n",
    "    \n",
    "    # Hyperparameters\n",
    "    filters = 32\n",
    "    shape = 5\n",
    "    stride = 2\n",
    "    pad ='same'\n",
    "    act = 'relu'    \n",
    "    n_classes = y_train[0].shape[1]\n",
    "    \n",
    "    # Layers to be frozen\n",
    "    feature_layers = [\n",
    "        Conv2D(filters, shape, strides=stride, padding=pad, activation=act,\n",
    "               input_shape=X_train.shape[1:]),\n",
    "        Conv2D(filters, shape, strides=stride, padding=pad, activation=act),\n",
    "        Conv2D(filters, shape, strides=stride, padding=pad, activation=act),\n",
    "        MaxPooling2D(pool_size=2),\n",
    "        Dropout(0.25),\n",
    "        Flatten()\n",
    "    ]\n",
    "    \n",
    "    # Classification layers\n",
    "    class_layers = [\n",
    "        Dense(512, activation=act),\n",
    "        Dense(n_classes, activation='softmax')\n",
    "    ]\n",
    "\n",
    "    # Simple CNN\n",
    "    model = Sequential(feature_layers + class_layers)\n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    print(\"Character 1\")\n",
    "    model.fit(X_train, y_train[0],\n",
    "                  batch_size=64,\n",
    "                  epochs=15,\n",
    "                  validation_data=(X_test, y_test[0]),\n",
    "                  shuffle=True)\n",
    "    print()\n",
    "    \n",
    "    # Save the prediction results\n",
    "    y_pred = pred_classes(model.predict(X_test))\n",
    "    results[:,0] = encoder.inverse_transform(y_pred).flatten()\n",
    "    \n",
    "    # Freeze the feature layers\n",
    "    for l in feature_layers:\n",
    "        l.trainable = False\n",
    "        \n",
    "    # Train the rest of the models using the frozen layers\n",
    "    for i in range(1,6):\n",
    "        print(f\"Character {i+1}\")\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        model.fit(X_train, y_train[i],\n",
    "                  batch_size=64,\n",
    "                  epochs=15,\n",
    "                  validation_data=(X_test, y_test[i]),\n",
    "                  shuffle=True)\n",
    "        y_pred = pred_classes(model.predict(X_test))\n",
    "        results[:,i] = encoder.inverse_transform(y_pred).flatten()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6bd2d7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 25, 125, 32)       832       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 63, 32)        25632     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 7, 32, 32)         25632     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 3, 16, 32)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 3, 16, 32)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1536)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               786944    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 21)                10773     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 849,813\n",
      "Trainable params: 849,813\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Character 1\n",
      "Epoch 1/15\n",
      "133/133 [==============================] - 18s 134ms/step - loss: 3.0454 - accuracy: 0.0492 - val_loss: 3.0340 - val_accuracy: 0.0587\n",
      "Epoch 2/15\n",
      "133/133 [==============================] - 16s 121ms/step - loss: 2.3088 - accuracy: 0.2630 - val_loss: 1.5364 - val_accuracy: 0.4667\n",
      "Epoch 3/15\n",
      "133/133 [==============================] - 16s 121ms/step - loss: 1.0508 - accuracy: 0.6359 - val_loss: 0.6678 - val_accuracy: 0.7773\n",
      "Epoch 4/15\n",
      "133/133 [==============================] - 17s 126ms/step - loss: 0.4991 - accuracy: 0.8298 - val_loss: 0.4333 - val_accuracy: 0.8527\n",
      "Epoch 5/15\n",
      "133/133 [==============================] - 16s 123ms/step - loss: 0.3054 - accuracy: 0.8926 - val_loss: 0.3598 - val_accuracy: 0.8800\n",
      "Epoch 6/15\n",
      "133/133 [==============================] - 16s 122ms/step - loss: 0.1958 - accuracy: 0.9322 - val_loss: 0.3594 - val_accuracy: 0.8787\n",
      "Epoch 7/15\n",
      "133/133 [==============================] - 19s 146ms/step - loss: 0.1662 - accuracy: 0.9437 - val_loss: 0.2759 - val_accuracy: 0.9220\n",
      "Epoch 8/15\n",
      "133/133 [==============================] - 18s 137ms/step - loss: 0.1178 - accuracy: 0.9622 - val_loss: 0.2621 - val_accuracy: 0.9180\n",
      "Epoch 9/15\n",
      "133/133 [==============================] - 16s 119ms/step - loss: 0.1076 - accuracy: 0.9637 - val_loss: 0.2684 - val_accuracy: 0.9120\n",
      "Epoch 10/15\n",
      "133/133 [==============================] - 16s 124ms/step - loss: 0.0870 - accuracy: 0.9714 - val_loss: 0.2578 - val_accuracy: 0.9180\n",
      "Epoch 11/15\n",
      "133/133 [==============================] - 17s 128ms/step - loss: 0.0681 - accuracy: 0.9773 - val_loss: 0.2677 - val_accuracy: 0.9200\n",
      "Epoch 12/15\n",
      "133/133 [==============================] - 16s 124ms/step - loss: 0.0675 - accuracy: 0.9782 - val_loss: 0.2755 - val_accuracy: 0.9233\n",
      "Epoch 13/15\n",
      "133/133 [==============================] - 15s 116ms/step - loss: 0.0548 - accuracy: 0.9820 - val_loss: 0.2809 - val_accuracy: 0.9273\n",
      "Epoch 14/15\n",
      "133/133 [==============================] - 16s 120ms/step - loss: 0.0579 - accuracy: 0.9805 - val_loss: 0.3107 - val_accuracy: 0.9180\n",
      "Epoch 15/15\n",
      "133/133 [==============================] - 18s 133ms/step - loss: 0.0495 - accuracy: 0.9828 - val_loss: 0.2473 - val_accuracy: 0.9353\n",
      "\n",
      "47/47 [==============================] - 1s 10ms/step\n",
      "Character 2\n",
      "Epoch 1/15\n",
      "133/133 [==============================] - 5s 35ms/step - loss: 5.0490 - accuracy: 0.1122 - val_loss: 2.4338 - val_accuracy: 0.2727\n",
      "Epoch 2/15\n",
      "133/133 [==============================] - 3s 26ms/step - loss: 1.7014 - accuracy: 0.4749 - val_loss: 1.1153 - val_accuracy: 0.6573\n",
      "Epoch 3/15\n",
      "133/133 [==============================] - 4s 30ms/step - loss: 0.9612 - accuracy: 0.7034 - val_loss: 0.8070 - val_accuracy: 0.7447\n",
      "Epoch 4/15\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 0.6725 - accuracy: 0.7898 - val_loss: 0.6652 - val_accuracy: 0.7960\n",
      "Epoch 5/15\n",
      "133/133 [==============================] - 4s 33ms/step - loss: 0.5141 - accuracy: 0.8443 - val_loss: 0.5858 - val_accuracy: 0.8127\n",
      "Epoch 6/15\n",
      "133/133 [==============================] - 4s 27ms/step - loss: 0.4013 - accuracy: 0.8788 - val_loss: 0.5277 - val_accuracy: 0.8373\n",
      "Epoch 7/15\n",
      "133/133 [==============================] - 3s 25ms/step - loss: 0.3232 - accuracy: 0.9050 - val_loss: 0.5043 - val_accuracy: 0.8407\n",
      "Epoch 8/15\n",
      "133/133 [==============================] - 3s 24ms/step - loss: 0.2665 - accuracy: 0.9250 - val_loss: 0.4831 - val_accuracy: 0.8440\n",
      "Epoch 9/15\n",
      "133/133 [==============================] - 3s 26ms/step - loss: 0.2079 - accuracy: 0.9429 - val_loss: 0.4833 - val_accuracy: 0.8473\n",
      "Epoch 10/15\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 0.1779 - accuracy: 0.9485 - val_loss: 0.4570 - val_accuracy: 0.8507\n",
      "Epoch 11/15\n",
      "133/133 [==============================] - 3s 25ms/step - loss: 0.1481 - accuracy: 0.9611 - val_loss: 0.4631 - val_accuracy: 0.8507\n",
      "Epoch 12/15\n",
      "133/133 [==============================] - 3s 25ms/step - loss: 0.1240 - accuracy: 0.9678 - val_loss: 0.4877 - val_accuracy: 0.8507\n",
      "Epoch 13/15\n",
      "133/133 [==============================] - 3s 24ms/step - loss: 0.1183 - accuracy: 0.9694 - val_loss: 0.4774 - val_accuracy: 0.8453\n",
      "Epoch 14/15\n",
      "133/133 [==============================] - 4s 30ms/step - loss: 0.1060 - accuracy: 0.9700 - val_loss: 0.5028 - val_accuracy: 0.8427\n",
      "Epoch 15/15\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 0.0966 - accuracy: 0.9746 - val_loss: 0.4943 - val_accuracy: 0.8540\n",
      "47/47 [==============================] - 2s 39ms/step\n",
      "Character 3\n",
      "Epoch 1/15\n",
      "133/133 [==============================] - 5s 32ms/step - loss: 5.4744 - accuracy: 0.0840 - val_loss: 2.7298 - val_accuracy: 0.1413\n",
      "Epoch 2/15\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 2.1285 - accuracy: 0.3302 - val_loss: 1.5459 - val_accuracy: 0.4953\n",
      "Epoch 3/15\n",
      "133/133 [==============================] - 3s 24ms/step - loss: 1.2082 - accuracy: 0.6102 - val_loss: 1.0492 - val_accuracy: 0.6587\n",
      "Epoch 4/15\n",
      "133/133 [==============================] - 5s 35ms/step - loss: 0.8220 - accuracy: 0.7411 - val_loss: 0.8526 - val_accuracy: 0.7273\n",
      "Epoch 5/15\n",
      "133/133 [==============================] - 4s 26ms/step - loss: 0.6309 - accuracy: 0.8041 - val_loss: 0.7552 - val_accuracy: 0.7640\n",
      "Epoch 6/15\n",
      "133/133 [==============================] - 4s 27ms/step - loss: 0.4874 - accuracy: 0.8479 - val_loss: 0.6785 - val_accuracy: 0.7893\n",
      "Epoch 7/15\n",
      "133/133 [==============================] - 4s 27ms/step - loss: 0.3838 - accuracy: 0.8855 - val_loss: 0.6804 - val_accuracy: 0.7800\n",
      "Epoch 8/15\n",
      "133/133 [==============================] - 3s 26ms/step - loss: 0.3047 - accuracy: 0.9100 - val_loss: 0.6605 - val_accuracy: 0.7820\n",
      "Epoch 9/15\n",
      "133/133 [==============================] - 4s 27ms/step - loss: 0.2414 - accuracy: 0.9322 - val_loss: 0.6255 - val_accuracy: 0.8007\n",
      "Epoch 10/15\n",
      "133/133 [==============================] - 4s 27ms/step - loss: 0.1941 - accuracy: 0.9459 - val_loss: 0.6222 - val_accuracy: 0.8013\n",
      "Epoch 11/15\n",
      "133/133 [==============================] - 4s 27ms/step - loss: 0.1627 - accuracy: 0.9532 - val_loss: 0.6265 - val_accuracy: 0.8027\n",
      "Epoch 12/15\n",
      "133/133 [==============================] - 4s 27ms/step - loss: 0.1435 - accuracy: 0.9613 - val_loss: 0.6325 - val_accuracy: 0.8000\n",
      "Epoch 13/15\n",
      "133/133 [==============================] - 4s 26ms/step - loss: 0.1165 - accuracy: 0.9714 - val_loss: 0.6384 - val_accuracy: 0.8020\n",
      "Epoch 14/15\n",
      "133/133 [==============================] - 3s 26ms/step - loss: 0.0968 - accuracy: 0.9742 - val_loss: 0.6463 - val_accuracy: 0.8007\n",
      "Epoch 15/15\n",
      "133/133 [==============================] - 4s 30ms/step - loss: 0.0886 - accuracy: 0.9768 - val_loss: 0.6526 - val_accuracy: 0.7980\n",
      "47/47 [==============================] - 1s 12ms/step\n",
      "Character 4\n",
      "Epoch 1/15\n",
      "133/133 [==============================] - 5s 32ms/step - loss: 5.5036 - accuracy: 0.0776 - val_loss: 2.8086 - val_accuracy: 0.1480\n",
      "Epoch 2/15\n",
      "133/133 [==============================] - 3s 24ms/step - loss: 2.4623 - accuracy: 0.2336 - val_loss: 2.0895 - val_accuracy: 0.3320\n",
      "Epoch 3/15\n",
      "133/133 [==============================] - 3s 24ms/step - loss: 1.6074 - accuracy: 0.4864 - val_loss: 1.3551 - val_accuracy: 0.5687\n",
      "Epoch 4/15\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 1.0729 - accuracy: 0.6556 - val_loss: 1.0686 - val_accuracy: 0.6553\n",
      "Epoch 5/15\n",
      "133/133 [==============================] - 4s 27ms/step - loss: 0.8120 - accuracy: 0.7367 - val_loss: 0.9054 - val_accuracy: 0.7167\n",
      "Epoch 6/15\n",
      "133/133 [==============================] - 4s 30ms/step - loss: 0.6194 - accuracy: 0.8024 - val_loss: 0.8345 - val_accuracy: 0.7353\n",
      "Epoch 7/15\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 0.5006 - accuracy: 0.8411 - val_loss: 0.7984 - val_accuracy: 0.7420\n",
      "Epoch 8/15\n",
      "133/133 [==============================] - 3s 26ms/step - loss: 0.4080 - accuracy: 0.8730 - val_loss: 0.7478 - val_accuracy: 0.7567\n",
      "Epoch 9/15\n",
      "133/133 [==============================] - 4s 27ms/step - loss: 0.3336 - accuracy: 0.8986 - val_loss: 0.7420 - val_accuracy: 0.7567\n",
      "Epoch 10/15\n",
      "133/133 [==============================] - 3s 24ms/step - loss: 0.2688 - accuracy: 0.9202 - val_loss: 0.7238 - val_accuracy: 0.7760\n",
      "Epoch 11/15\n",
      "133/133 [==============================] - 3s 24ms/step - loss: 0.2249 - accuracy: 0.9338 - val_loss: 0.7144 - val_accuracy: 0.7727\n",
      "Epoch 12/15\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 0.1941 - accuracy: 0.9415 - val_loss: 0.7003 - val_accuracy: 0.7787\n",
      "Epoch 13/15\n",
      "133/133 [==============================] - 6s 43ms/step - loss: 0.1595 - accuracy: 0.9553 - val_loss: 0.7308 - val_accuracy: 0.7820\n",
      "Epoch 14/15\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 0.1424 - accuracy: 0.9613 - val_loss: 0.7197 - val_accuracy: 0.7840\n",
      "Epoch 15/15\n",
      "133/133 [==============================] - 3s 25ms/step - loss: 0.1201 - accuracy: 0.9660 - val_loss: 0.7411 - val_accuracy: 0.7760\n",
      "47/47 [==============================] - 1s 16ms/step\n",
      "Character 5\n",
      "Epoch 1/15\n",
      "133/133 [==============================] - 6s 39ms/step - loss: 5.5032 - accuracy: 0.0662 - val_loss: 2.9157 - val_accuracy: 0.1133\n",
      "Epoch 2/15\n",
      "133/133 [==============================] - 3s 24ms/step - loss: 2.7341 - accuracy: 0.1573 - val_loss: 2.4433 - val_accuracy: 0.2327\n",
      "Epoch 3/15\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 2.0711 - accuracy: 0.3442 - val_loss: 1.6780 - val_accuracy: 0.4540\n",
      "Epoch 4/15\n",
      "133/133 [==============================] - 3s 25ms/step - loss: 1.3968 - accuracy: 0.5590 - val_loss: 1.1946 - val_accuracy: 0.6120\n",
      "Epoch 5/15\n",
      "133/133 [==============================] - 3s 23ms/step - loss: 1.0082 - accuracy: 0.6732 - val_loss: 0.9451 - val_accuracy: 0.6967\n",
      "Epoch 6/15\n",
      "133/133 [==============================] - 3s 24ms/step - loss: 0.7811 - accuracy: 0.7501 - val_loss: 0.8316 - val_accuracy: 0.7333\n",
      "Epoch 7/15\n",
      "133/133 [==============================] - 3s 25ms/step - loss: 0.6285 - accuracy: 0.8040 - val_loss: 0.7455 - val_accuracy: 0.7627\n",
      "Epoch 8/15\n",
      "133/133 [==============================] - 3s 23ms/step - loss: 0.5244 - accuracy: 0.8384 - val_loss: 0.7216 - val_accuracy: 0.7640\n",
      "Epoch 9/15\n",
      "133/133 [==============================] - 3s 26ms/step - loss: 0.4212 - accuracy: 0.8725 - val_loss: 0.6952 - val_accuracy: 0.7787\n",
      "Epoch 10/15\n",
      "133/133 [==============================] - 5s 38ms/step - loss: 0.3503 - accuracy: 0.8932 - val_loss: 0.6708 - val_accuracy: 0.7820\n",
      "Epoch 11/15\n",
      "133/133 [==============================] - 5s 34ms/step - loss: 0.2928 - accuracy: 0.9139 - val_loss: 0.6643 - val_accuracy: 0.7887\n",
      "Epoch 12/15\n",
      "133/133 [==============================] - 4s 31ms/step - loss: 0.2534 - accuracy: 0.9235 - val_loss: 0.6510 - val_accuracy: 0.7973\n",
      "Epoch 13/15\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 0.2130 - accuracy: 0.9394 - val_loss: 0.6550 - val_accuracy: 0.7927\n",
      "Epoch 14/15\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 0.1827 - accuracy: 0.9493 - val_loss: 0.6771 - val_accuracy: 0.8020\n",
      "Epoch 15/15\n",
      "133/133 [==============================] - 4s 33ms/step - loss: 0.1551 - accuracy: 0.9573 - val_loss: 0.6548 - val_accuracy: 0.8040\n",
      "47/47 [==============================] - 1s 19ms/step\n",
      "Character 6\n",
      "Epoch 1/15\n",
      "133/133 [==============================] - 6s 39ms/step - loss: 5.4932 - accuracy: 0.0718 - val_loss: 2.8596 - val_accuracy: 0.1213\n",
      "Epoch 2/15\n",
      "133/133 [==============================] - 4s 31ms/step - loss: 2.6069 - accuracy: 0.1999 - val_loss: 2.1575 - val_accuracy: 0.3153\n",
      "Epoch 3/15\n",
      "133/133 [==============================] - 3s 26ms/step - loss: 1.7185 - accuracy: 0.4425 - val_loss: 1.2613 - val_accuracy: 0.5980\n",
      "Epoch 4/15\n",
      "133/133 [==============================] - 3s 26ms/step - loss: 1.0211 - accuracy: 0.6593 - val_loss: 0.8253 - val_accuracy: 0.7400\n",
      "Epoch 5/15\n",
      "133/133 [==============================] - 3s 26ms/step - loss: 0.6876 - accuracy: 0.7777 - val_loss: 0.6598 - val_accuracy: 0.7927\n",
      "Epoch 6/15\n",
      "133/133 [==============================] - 4s 30ms/step - loss: 0.5140 - accuracy: 0.8384 - val_loss: 0.5796 - val_accuracy: 0.8180\n",
      "Epoch 7/15\n",
      "133/133 [==============================] - 3s 24ms/step - loss: 0.4255 - accuracy: 0.8690 - val_loss: 0.5075 - val_accuracy: 0.8427\n",
      "Epoch 8/15\n",
      "133/133 [==============================] - 3s 25ms/step - loss: 0.3369 - accuracy: 0.8980 - val_loss: 0.4575 - val_accuracy: 0.8633\n",
      "Epoch 9/15\n",
      "133/133 [==============================] - 3s 26ms/step - loss: 0.2709 - accuracy: 0.9194 - val_loss: 0.4379 - val_accuracy: 0.8740\n",
      "Epoch 10/15\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 0.2491 - accuracy: 0.9269 - val_loss: 0.4075 - val_accuracy: 0.8760\n",
      "Epoch 11/15\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 0.1962 - accuracy: 0.9452 - val_loss: 0.3927 - val_accuracy: 0.8787\n",
      "Epoch 12/15\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 0.1684 - accuracy: 0.9532 - val_loss: 0.3797 - val_accuracy: 0.8880\n",
      "Epoch 13/15\n",
      "133/133 [==============================] - 4s 31ms/step - loss: 0.1468 - accuracy: 0.9589 - val_loss: 0.3751 - val_accuracy: 0.8927\n",
      "Epoch 14/15\n",
      "133/133 [==============================] - 3s 26ms/step - loss: 0.1312 - accuracy: 0.9619 - val_loss: 0.3842 - val_accuracy: 0.8860\n",
      "Epoch 15/15\n",
      "133/133 [==============================] - 3s 25ms/step - loss: 0.1201 - accuracy: 0.9674 - val_loss: 0.3825 - val_accuracy: 0.8820\n",
      "47/47 [==============================] - 0s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "results = train_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "952a139a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False,  True, False,  True,  True],\n",
       "       [ True,  True, False,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True],\n",
       "       ...,\n",
       "       [ True,  True, False,  True, False,  True],\n",
       "       [ True, False,  True,  True,  True,  True],\n",
       "       [ True, False,  True,  True,  True,  True]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results == labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35bf22dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_accuracy(y_true, y_pred):\n",
    "    bool_array = y_true == y_pred\n",
    "    total = np.sum(bool_array) / y_true.size\n",
    "    per_label = [np.all(y_true[i] == y_pred[i]) for i in range(len(y_true))]\n",
    "    per_label = np.sum(per_label) / len(y_true)\n",
    "    print(f\"Per Character Accuracy: {total:.2%}\")\n",
    "    print(f\"Per Label Accuracy: {per_label:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "50f7e02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per Character Accuracy: 84.16%\n",
      "Per Label Accuracy: 44.67%\n"
     ]
    }
   ],
   "source": [
    "label_accuracy(labels_test, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a2e51ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all models\n",
    "def train_model(X_train, X_test, y_train, y_test):\n",
    "    # Clear the current model\n",
    "    keras.backend.clear_session()\n",
    "    \n",
    "    # Store test results\n",
    "    results = np.zeros((y_test[0].shape[0], 6), dtype=object)\n",
    "    \n",
    "    # Hyperparameters\n",
    "    filters = 32\n",
    "    shape = 5\n",
    "    stride = 2\n",
    "    pad ='same'\n",
    "    act = 'relu'    \n",
    "    n_classes = y_train[0].shape[1]\n",
    "    \n",
    "    # Layers to be frozen\n",
    "    feature_layers = [\n",
    "        Conv2D(filters, shape, strides=stride, padding=pad, activation=act,\n",
    "               input_shape=X_train.shape[1:]),\n",
    "        Conv2D(filters, shape, strides=stride, padding=pad, activation=act),\n",
    "        Conv2D(filters, shape, strides=stride, padding=pad, activation=act),\n",
    "        MaxPooling2D(pool_size=2),\n",
    "        Dropout(0.25),\n",
    "        Flatten()\n",
    "    ]\n",
    "    \n",
    "    # Classification layers\n",
    "    class_layers = [\n",
    "        Dense(512, activation=act),\n",
    "        Dropout(0.25),\n",
    "        Dense(256, activation=act),\n",
    "        Dense(n_classes, activation='softmax')\n",
    "    ]\n",
    "\n",
    "    # Simple CNN\n",
    "    model = Sequential(feature_layers + class_layers)\n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    print(\"Character 1\")\n",
    "    model.fit(X_train, y_train[0],\n",
    "                  batch_size=64,\n",
    "                  epochs=15,\n",
    "                  validation_data=(X_test, y_test[0]),\n",
    "                  shuffle=True)\n",
    "    \n",
    "    # Save the prediction results\n",
    "    y_pred = pred_classes(model.predict(X_test))\n",
    "    results[:,0] = encoder.inverse_transform(y_pred).flatten()\n",
    "    print()\n",
    "    \n",
    "    # Freeze the feature layers\n",
    "    for l in feature_layers:\n",
    "        l.trainable = False\n",
    "        \n",
    "    # Train the rest of the models using the frozen layers\n",
    "    for i in range(1,6):\n",
    "        print(f\"Character {i+1}\")\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        model.fit(X_train, y_train[i],\n",
    "                  batch_size=64,\n",
    "                  epochs=15,\n",
    "                  validation_data=(X_test, y_test[i]),\n",
    "                  shuffle=True)\n",
    "        y_pred = pred_classes(model.predict(X_test))\n",
    "        results[:,i] = encoder.inverse_transform(y_pred).flatten()\n",
    "        print()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e989c8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 25, 125, 32)       832       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 63, 32)        25632     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 7, 32, 32)         25632     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 3, 16, 32)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 3, 16, 32)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1536)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               786944    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 21)                5397      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 975,765\n",
      "Trainable params: 975,765\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Character 1\n",
      "Epoch 1/15\n",
      "133/133 [==============================] - 18s 131ms/step - loss: 3.0453 - accuracy: 0.0483 - val_loss: 3.0447 - val_accuracy: 0.0453\n",
      "Epoch 2/15\n",
      "133/133 [==============================] - 16s 124ms/step - loss: 3.0442 - accuracy: 0.0500 - val_loss: 3.0452 - val_accuracy: 0.0453\n",
      "Epoch 3/15\n",
      "133/133 [==============================] - 16s 121ms/step - loss: 2.8692 - accuracy: 0.1045 - val_loss: 2.3105 - val_accuracy: 0.2453\n",
      "Epoch 4/15\n",
      "133/133 [==============================] - 16s 123ms/step - loss: 1.5610 - accuracy: 0.4771 - val_loss: 0.8236 - val_accuracy: 0.7253\n",
      "Epoch 5/15\n",
      "133/133 [==============================] - 17s 125ms/step - loss: 0.7142 - accuracy: 0.7546 - val_loss: 0.4538 - val_accuracy: 0.8507\n",
      "Epoch 6/15\n",
      "133/133 [==============================] - 18s 136ms/step - loss: 0.3968 - accuracy: 0.8674 - val_loss: 0.3175 - val_accuracy: 0.8933\n",
      "Epoch 7/15\n",
      "133/133 [==============================] - 17s 126ms/step - loss: 0.2637 - accuracy: 0.9105 - val_loss: 0.2278 - val_accuracy: 0.9240\n",
      "Epoch 8/15\n",
      "133/133 [==============================] - 16s 120ms/step - loss: 0.2022 - accuracy: 0.9305 - val_loss: 0.2198 - val_accuracy: 0.9293\n",
      "Epoch 9/15\n",
      "133/133 [==============================] - 14s 107ms/step - loss: 0.1610 - accuracy: 0.9460 - val_loss: 0.2439 - val_accuracy: 0.9213\n",
      "Epoch 10/15\n",
      "133/133 [==============================] - 19s 141ms/step - loss: 0.1739 - accuracy: 0.9425 - val_loss: 0.2478 - val_accuracy: 0.9240\n",
      "Epoch 11/15\n",
      "133/133 [==============================] - 17s 131ms/step - loss: 0.1334 - accuracy: 0.9562 - val_loss: 0.1879 - val_accuracy: 0.9440\n",
      "Epoch 12/15\n",
      "133/133 [==============================] - 17s 130ms/step - loss: 0.0912 - accuracy: 0.9689 - val_loss: 0.1654 - val_accuracy: 0.9460\n",
      "Epoch 13/15\n",
      "133/133 [==============================] - 16s 118ms/step - loss: 0.0823 - accuracy: 0.9720 - val_loss: 0.2113 - val_accuracy: 0.9360\n",
      "Epoch 14/15\n",
      "133/133 [==============================] - 18s 134ms/step - loss: 0.0847 - accuracy: 0.9713 - val_loss: 0.1922 - val_accuracy: 0.9360\n",
      "Epoch 15/15\n",
      "133/133 [==============================] - 17s 128ms/step - loss: 0.0705 - accuracy: 0.9774 - val_loss: 0.1886 - val_accuracy: 0.9467\n",
      "\n",
      "47/47 [==============================] - 1s 25ms/step\n",
      "Character 2\n",
      "Epoch 1/15\n",
      "133/133 [==============================] - 6s 41ms/step - loss: 4.4814 - accuracy: 0.1022 - val_loss: 2.4258 - val_accuracy: 0.2740\n",
      "Epoch 2/15\n",
      "133/133 [==============================] - 4s 30ms/step - loss: 2.0653 - accuracy: 0.3422 - val_loss: 1.3979 - val_accuracy: 0.5807\n",
      "Epoch 3/15\n",
      "133/133 [==============================] - 4s 27ms/step - loss: 1.4397 - accuracy: 0.5303 - val_loss: 1.0377 - val_accuracy: 0.6813\n",
      "Epoch 4/15\n",
      "133/133 [==============================] - 4s 30ms/step - loss: 1.1173 - accuracy: 0.6325 - val_loss: 0.8486 - val_accuracy: 0.7307\n",
      "Epoch 5/15\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 0.8856 - accuracy: 0.7139 - val_loss: 0.7590 - val_accuracy: 0.7560\n",
      "Epoch 6/15\n",
      "133/133 [==============================] - 4s 30ms/step - loss: 0.7262 - accuracy: 0.7644 - val_loss: 0.6766 - val_accuracy: 0.7833\n",
      "Epoch 7/15\n",
      "133/133 [==============================] - 4s 34ms/step - loss: 0.6128 - accuracy: 0.7992 - val_loss: 0.6161 - val_accuracy: 0.7987\n",
      "Epoch 8/15\n",
      "133/133 [==============================] - 4s 31ms/step - loss: 0.5086 - accuracy: 0.8337 - val_loss: 0.5810 - val_accuracy: 0.8100\n",
      "Epoch 9/15\n",
      "133/133 [==============================] - 4s 30ms/step - loss: 0.4389 - accuracy: 0.8557 - val_loss: 0.5714 - val_accuracy: 0.8240\n",
      "Epoch 10/15\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 0.3982 - accuracy: 0.8659 - val_loss: 0.5607 - val_accuracy: 0.8213\n",
      "Epoch 11/15\n",
      "133/133 [==============================] - 5s 41ms/step - loss: 0.3272 - accuracy: 0.8914 - val_loss: 0.5481 - val_accuracy: 0.8307\n",
      "Epoch 12/15\n",
      "133/133 [==============================] - 5s 36ms/step - loss: 0.3097 - accuracy: 0.8928 - val_loss: 0.5649 - val_accuracy: 0.8300\n",
      "Epoch 13/15\n",
      "133/133 [==============================] - 4s 30ms/step - loss: 0.2670 - accuracy: 0.9132 - val_loss: 0.5808 - val_accuracy: 0.8287\n",
      "Epoch 14/15\n",
      "133/133 [==============================] - 4s 31ms/step - loss: 0.2339 - accuracy: 0.9239 - val_loss: 0.5513 - val_accuracy: 0.8380\n",
      "Epoch 15/15\n",
      "133/133 [==============================] - 5s 38ms/step - loss: 0.2264 - accuracy: 0.9241 - val_loss: 0.6124 - val_accuracy: 0.8293\n",
      "47/47 [==============================] - 1s 11ms/step\n",
      "Character 3\n",
      "Epoch 1/15\n",
      "133/133 [==============================] - 5s 36ms/step - loss: 4.0986 - accuracy: 0.0880 - val_loss: 2.6621 - val_accuracy: 0.2113\n",
      "Epoch 2/15\n",
      "133/133 [==============================] - 4s 26ms/step - loss: 2.3388 - accuracy: 0.2709 - val_loss: 1.7785 - val_accuracy: 0.4807\n",
      "Epoch 3/15\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 1.6762 - accuracy: 0.4661 - val_loss: 1.2812 - val_accuracy: 0.6307\n",
      "Epoch 4/15\n",
      "133/133 [==============================] - 3s 26ms/step - loss: 1.3126 - accuracy: 0.5802 - val_loss: 1.0650 - val_accuracy: 0.6733\n",
      "Epoch 5/15\n",
      "133/133 [==============================] - 4s 26ms/step - loss: 1.0701 - accuracy: 0.6465 - val_loss: 0.9394 - val_accuracy: 0.7100\n",
      "Epoch 6/15\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 0.8963 - accuracy: 0.7107 - val_loss: 0.8484 - val_accuracy: 0.7467\n",
      "Epoch 7/15\n",
      "133/133 [==============================] - 3s 25ms/step - loss: 0.7398 - accuracy: 0.7604 - val_loss: 0.7866 - val_accuracy: 0.7627\n",
      "Epoch 8/15\n",
      "133/133 [==============================] - 5s 40ms/step - loss: 0.6552 - accuracy: 0.7843 - val_loss: 0.7566 - val_accuracy: 0.7707\n",
      "Epoch 9/15\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 0.5506 - accuracy: 0.8236 - val_loss: 0.7259 - val_accuracy: 0.7720\n",
      "Epoch 10/15\n",
      "133/133 [==============================] - 5s 35ms/step - loss: 0.4781 - accuracy: 0.8453 - val_loss: 0.7286 - val_accuracy: 0.7860\n",
      "Epoch 11/15\n",
      "133/133 [==============================] - 9s 65ms/step - loss: 0.4119 - accuracy: 0.8654 - val_loss: 0.7174 - val_accuracy: 0.7780\n",
      "Epoch 12/15\n",
      "133/133 [==============================] - 7s 51ms/step - loss: 0.3659 - accuracy: 0.8805 - val_loss: 0.7165 - val_accuracy: 0.7827\n",
      "Epoch 13/15\n",
      "133/133 [==============================] - 4s 34ms/step - loss: 0.3255 - accuracy: 0.8930 - val_loss: 0.7102 - val_accuracy: 0.7913\n",
      "Epoch 14/15\n",
      "133/133 [==============================] - 4s 31ms/step - loss: 0.2924 - accuracy: 0.9048 - val_loss: 0.7394 - val_accuracy: 0.7713\n",
      "Epoch 15/15\n",
      "133/133 [==============================] - 4s 27ms/step - loss: 0.2884 - accuracy: 0.9068 - val_loss: 0.7196 - val_accuracy: 0.7840\n",
      "47/47 [==============================] - 1s 12ms/step\n",
      "Character 4\n",
      "Epoch 1/15\n",
      "133/133 [==============================] - 6s 40ms/step - loss: 4.2808 - accuracy: 0.0642 - val_loss: 2.9296 - val_accuracy: 0.1187\n",
      "Epoch 2/15\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 2.7321 - accuracy: 0.1655 - val_loss: 2.4337 - val_accuracy: 0.2680\n",
      "Epoch 3/15\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 2.1920 - accuracy: 0.3166 - val_loss: 1.8385 - val_accuracy: 0.4520\n",
      "Epoch 4/15\n",
      "133/133 [==============================] - 5s 36ms/step - loss: 1.6859 - accuracy: 0.4652 - val_loss: 1.4334 - val_accuracy: 0.5607\n",
      "Epoch 5/15\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 1.3665 - accuracy: 0.5550 - val_loss: 1.2008 - val_accuracy: 0.6300\n",
      "Epoch 6/15\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 1.1442 - accuracy: 0.6360 - val_loss: 1.0774 - val_accuracy: 0.6547\n",
      "Epoch 7/15\n",
      "133/133 [==============================] - 4s 34ms/step - loss: 0.9610 - accuracy: 0.6880 - val_loss: 0.9777 - val_accuracy: 0.6887\n",
      "Epoch 8/15\n",
      "133/133 [==============================] - 4s 30ms/step - loss: 0.8245 - accuracy: 0.7293 - val_loss: 0.9197 - val_accuracy: 0.7120\n",
      "Epoch 9/15\n",
      "133/133 [==============================] - 4s 31ms/step - loss: 0.7127 - accuracy: 0.7644 - val_loss: 0.8758 - val_accuracy: 0.7247\n",
      "Epoch 10/15\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 0.6262 - accuracy: 0.7938 - val_loss: 0.8411 - val_accuracy: 0.7427\n",
      "Epoch 11/15\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 0.5365 - accuracy: 0.8268 - val_loss: 0.8073 - val_accuracy: 0.7560\n",
      "Epoch 12/15\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 0.5001 - accuracy: 0.8340 - val_loss: 0.7939 - val_accuracy: 0.7580\n",
      "Epoch 13/15\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 0.4632 - accuracy: 0.8486 - val_loss: 0.8239 - val_accuracy: 0.7547\n",
      "Epoch 14/15\n",
      "133/133 [==============================] - 5s 34ms/step - loss: 0.3925 - accuracy: 0.8726 - val_loss: 0.7838 - val_accuracy: 0.7640\n",
      "Epoch 15/15\n",
      "133/133 [==============================] - 5s 35ms/step - loss: 0.3520 - accuracy: 0.8870 - val_loss: 0.7740 - val_accuracy: 0.7660\n",
      "47/47 [==============================] - 1s 18ms/step\n",
      "Character 5\n",
      "Epoch 1/15\n",
      "133/133 [==============================] - 6s 45ms/step - loss: 4.3137 - accuracy: 0.0576 - val_loss: 2.9774 - val_accuracy: 0.0827\n",
      "Epoch 2/15\n",
      "133/133 [==============================] - 5s 34ms/step - loss: 2.8888 - accuracy: 0.1243 - val_loss: 2.6495 - val_accuracy: 0.2233\n",
      "Epoch 3/15\n",
      "133/133 [==============================] - 5s 37ms/step - loss: 2.4009 - accuracy: 0.2461 - val_loss: 1.9354 - val_accuracy: 0.4280\n",
      "Epoch 4/15\n",
      "133/133 [==============================] - 4s 30ms/step - loss: 1.8728 - accuracy: 0.4074 - val_loss: 1.4826 - val_accuracy: 0.5453\n",
      "Epoch 5/15\n",
      "133/133 [==============================] - 4s 27ms/step - loss: 1.5142 - accuracy: 0.5119 - val_loss: 1.2271 - val_accuracy: 0.6227\n",
      "Epoch 6/15\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 1.2702 - accuracy: 0.5896 - val_loss: 1.0661 - val_accuracy: 0.6740\n",
      "Epoch 7/15\n",
      "133/133 [==============================] - 4s 33ms/step - loss: 1.0903 - accuracy: 0.6445 - val_loss: 0.9338 - val_accuracy: 0.7207\n",
      "Epoch 8/15\n",
      "133/133 [==============================] - 4s 31ms/step - loss: 0.9262 - accuracy: 0.6992 - val_loss: 0.8558 - val_accuracy: 0.7427\n",
      "Epoch 9/15\n",
      "133/133 [==============================] - 4s 30ms/step - loss: 0.8229 - accuracy: 0.7351 - val_loss: 0.8094 - val_accuracy: 0.7520\n",
      "Epoch 10/15\n",
      "133/133 [==============================] - 4s 34ms/step - loss: 0.7132 - accuracy: 0.7664 - val_loss: 0.7667 - val_accuracy: 0.7640\n",
      "Epoch 11/15\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 0.6052 - accuracy: 0.8048 - val_loss: 0.7150 - val_accuracy: 0.7813\n",
      "Epoch 12/15\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 0.5405 - accuracy: 0.8248 - val_loss: 0.6958 - val_accuracy: 0.7800\n",
      "Epoch 13/15\n",
      "133/133 [==============================] - 4s 31ms/step - loss: 0.4732 - accuracy: 0.8478 - val_loss: 0.7042 - val_accuracy: 0.7773\n",
      "Epoch 14/15\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 0.4476 - accuracy: 0.8553 - val_loss: 0.6774 - val_accuracy: 0.7847\n",
      "Epoch 15/15\n",
      "133/133 [==============================] - 4s 27ms/step - loss: 0.3955 - accuracy: 0.8727 - val_loss: 0.6535 - val_accuracy: 0.7933\n",
      "47/47 [==============================] - 2s 42ms/step\n",
      "Character 6\n",
      "Epoch 1/15\n",
      "133/133 [==============================] - 6s 42ms/step - loss: 4.3911 - accuracy: 0.0702 - val_loss: 2.8522 - val_accuracy: 0.1307\n",
      "Epoch 2/15\n",
      "133/133 [==============================] - 4s 33ms/step - loss: 2.6740 - accuracy: 0.1803 - val_loss: 2.2613 - val_accuracy: 0.3220\n",
      "Epoch 3/15\n",
      "133/133 [==============================] - 4s 34ms/step - loss: 2.0383 - accuracy: 0.3550 - val_loss: 1.5414 - val_accuracy: 0.5240\n",
      "Epoch 4/15\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 1.5005 - accuracy: 0.5104 - val_loss: 1.1046 - val_accuracy: 0.6633\n",
      "Epoch 5/15\n",
      "133/133 [==============================] - 5s 38ms/step - loss: 1.1508 - accuracy: 0.6179 - val_loss: 0.8712 - val_accuracy: 0.7413\n",
      "Epoch 6/15\n",
      "133/133 [==============================] - 4s 33ms/step - loss: 0.9435 - accuracy: 0.6917 - val_loss: 0.7347 - val_accuracy: 0.7900\n",
      "Epoch 7/15\n",
      "133/133 [==============================] - 4s 30ms/step - loss: 0.7929 - accuracy: 0.7396 - val_loss: 0.6424 - val_accuracy: 0.8013\n",
      "Epoch 8/15\n",
      "133/133 [==============================] - 5s 34ms/step - loss: 0.6615 - accuracy: 0.7800 - val_loss: 0.5751 - val_accuracy: 0.8260\n",
      "Epoch 9/15\n",
      "133/133 [==============================] - 4s 34ms/step - loss: 0.5701 - accuracy: 0.8099 - val_loss: 0.5303 - val_accuracy: 0.8440\n",
      "Epoch 10/15\n",
      "133/133 [==============================] - 5s 35ms/step - loss: 0.4997 - accuracy: 0.8319 - val_loss: 0.5139 - val_accuracy: 0.8460\n",
      "Epoch 11/15\n",
      "133/133 [==============================] - 4s 31ms/step - loss: 0.4205 - accuracy: 0.8620 - val_loss: 0.4929 - val_accuracy: 0.8487\n",
      "Epoch 12/15\n",
      "133/133 [==============================] - 4s 33ms/step - loss: 0.3744 - accuracy: 0.8813 - val_loss: 0.4748 - val_accuracy: 0.8587\n",
      "Epoch 13/15\n",
      "133/133 [==============================] - 5s 35ms/step - loss: 0.3391 - accuracy: 0.8846 - val_loss: 0.4605 - val_accuracy: 0.8647\n",
      "Epoch 14/15\n",
      "133/133 [==============================] - 4s 31ms/step - loss: 0.3062 - accuracy: 0.8955 - val_loss: 0.4454 - val_accuracy: 0.8680\n",
      "Epoch 15/15\n",
      "133/133 [==============================] - 4s 30ms/step - loss: 0.2595 - accuracy: 0.9137 - val_loss: 0.4481 - val_accuracy: 0.8647\n",
      "47/47 [==============================] - 1s 13ms/step\n"
     ]
    }
   ],
   "source": [
    "results_2 = train_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c761b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per Character Accuracy: 83.07%\n",
      "Per Label Accuracy: 42.93%\n"
     ]
    }
   ],
   "source": [
    "label_accuracy(labels_test, results_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8db1a0ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.convolutional.conv2d.Conv2D at 0x7fae8ed4d3d0>,\n",
       " <keras.layers.pooling.max_pooling2d.MaxPooling2D at 0x7fae8ede7ad0>,\n",
       " <keras.layers.reshaping.flatten.Flatten at 0x7fae8e63dfd0>,\n",
       " <keras.layers.core.dense.Dense at 0x7faec8ef6d50>,\n",
       " <keras.layers.core.dense.Dense at 0x7faec8d12ad0>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38d80d26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 25, 125, 32)       832       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 63, 32)        25632     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 7, 32, 32)         25632     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 3, 16, 32)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 3, 16, 32)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1536)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               786944    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 21)                10773     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 849,813\n",
      "Trainable params: 849,813\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Character 1\n",
      "Epoch 1/15\n",
      "133/133 [==============================] - 18s 129ms/step - loss: 3.0462 - accuracy: 0.0509 - val_loss: 3.0391 - val_accuracy: 0.0613\n",
      "Epoch 2/15\n",
      "133/133 [==============================] - 15s 115ms/step - loss: 2.4485 - accuracy: 0.2266 - val_loss: 1.5066 - val_accuracy: 0.5107\n",
      "Epoch 3/15\n",
      "133/133 [==============================] - 16s 119ms/step - loss: 1.1317 - accuracy: 0.6256 - val_loss: 0.6210 - val_accuracy: 0.8020\n",
      "Epoch 4/15\n",
      "133/133 [==============================] - 17s 126ms/step - loss: 0.6047 - accuracy: 0.8016 - val_loss: 0.4673 - val_accuracy: 0.8527\n",
      "Epoch 5/15\n",
      "133/133 [==============================] - 19s 146ms/step - loss: 0.4088 - accuracy: 0.8635 - val_loss: 0.3721 - val_accuracy: 0.8800\n",
      "Epoch 6/15\n",
      "133/133 [==============================] - 19s 141ms/step - loss: 0.3042 - accuracy: 0.8995 - val_loss: 0.3007 - val_accuracy: 0.9087\n",
      "Epoch 7/15\n",
      "133/133 [==============================] - 14s 108ms/step - loss: 0.2528 - accuracy: 0.9132 - val_loss: 0.2997 - val_accuracy: 0.9047\n",
      "Epoch 8/15\n",
      "133/133 [==============================] - 18s 134ms/step - loss: 0.2059 - accuracy: 0.9325 - val_loss: 0.2518 - val_accuracy: 0.9193\n",
      "Epoch 9/15\n",
      "133/133 [==============================] - 16s 124ms/step - loss: 0.1513 - accuracy: 0.9480 - val_loss: 0.2440 - val_accuracy: 0.9193\n",
      "Epoch 10/15\n",
      "133/133 [==============================] - 18s 133ms/step - loss: 0.1436 - accuracy: 0.9502 - val_loss: 0.2409 - val_accuracy: 0.9200\n",
      "Epoch 11/15\n",
      "133/133 [==============================] - 16s 124ms/step - loss: 0.1121 - accuracy: 0.9626 - val_loss: 0.2534 - val_accuracy: 0.9267\n",
      "Epoch 12/15\n",
      "133/133 [==============================] - 18s 135ms/step - loss: 0.1072 - accuracy: 0.9629 - val_loss: 0.2408 - val_accuracy: 0.9233\n",
      "Epoch 13/15\n",
      "133/133 [==============================] - 16s 117ms/step - loss: 0.0952 - accuracy: 0.9695 - val_loss: 0.2464 - val_accuracy: 0.9227\n",
      "Epoch 14/15\n",
      "133/133 [==============================] - 16s 120ms/step - loss: 0.0866 - accuracy: 0.9717 - val_loss: 0.2336 - val_accuracy: 0.9313\n",
      "Epoch 15/15\n",
      "133/133 [==============================] - 17s 127ms/step - loss: 0.0759 - accuracy: 0.9748 - val_loss: 0.2504 - val_accuracy: 0.9260\n",
      "47/47 [==============================] - 1s 18ms/step\n",
      "\n",
      "Character 2\n",
      "Epoch 1/10\n",
      "133/133 [==============================] - 5s 36ms/step - loss: 4.9801 - accuracy: 0.0762 - val_loss: 2.7335 - val_accuracy: 0.2000\n",
      "Epoch 2/10\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 2.3844 - accuracy: 0.2751 - val_loss: 1.7358 - val_accuracy: 0.4740\n",
      "Epoch 3/10\n",
      "133/133 [==============================] - 3s 26ms/step - loss: 1.6851 - accuracy: 0.4722 - val_loss: 1.2472 - val_accuracy: 0.6240\n",
      "Epoch 4/10\n",
      "133/133 [==============================] - 3s 23ms/step - loss: 1.3068 - accuracy: 0.5950 - val_loss: 1.0102 - val_accuracy: 0.7040\n",
      "Epoch 5/10\n",
      "133/133 [==============================] - 3s 24ms/step - loss: 1.0713 - accuracy: 0.6623 - val_loss: 0.8635 - val_accuracy: 0.7540\n",
      "Epoch 6/10\n",
      "133/133 [==============================] - 3s 25ms/step - loss: 0.8692 - accuracy: 0.7311 - val_loss: 0.7480 - val_accuracy: 0.7767\n",
      "Epoch 7/10\n",
      "133/133 [==============================] - 3s 23ms/step - loss: 0.7544 - accuracy: 0.7592 - val_loss: 0.6753 - val_accuracy: 0.8013\n",
      "Epoch 8/10\n",
      "133/133 [==============================] - 4s 27ms/step - loss: 0.6351 - accuracy: 0.7992 - val_loss: 0.6440 - val_accuracy: 0.8087\n",
      "Epoch 9/10\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 0.5433 - accuracy: 0.8308 - val_loss: 0.6006 - val_accuracy: 0.8247\n",
      "Epoch 10/10\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 0.4790 - accuracy: 0.8503 - val_loss: 0.5814 - val_accuracy: 0.8153\n",
      "Epoch 1/5\n",
      "133/133 [==============================] - 16s 118ms/step - loss: 0.3988 - accuracy: 0.8750 - val_loss: 0.5556 - val_accuracy: 0.8253\n",
      "Epoch 2/5\n",
      "133/133 [==============================] - 17s 126ms/step - loss: 0.3747 - accuracy: 0.8835 - val_loss: 0.5407 - val_accuracy: 0.8293\n",
      "Epoch 3/5\n",
      "133/133 [==============================] - 14s 103ms/step - loss: 0.3767 - accuracy: 0.8845 - val_loss: 0.5295 - val_accuracy: 0.8313\n",
      "Epoch 4/5\n",
      "133/133 [==============================] - 12s 91ms/step - loss: 0.3739 - accuracy: 0.8811 - val_loss: 0.5207 - val_accuracy: 0.8333\n",
      "Epoch 5/5\n",
      "133/133 [==============================] - 16s 121ms/step - loss: 0.3533 - accuracy: 0.8913 - val_loss: 0.5142 - val_accuracy: 0.8347\n",
      "47/47 [==============================] - 1s 12ms/step\n",
      "\n",
      "Character 3\n",
      "Epoch 1/10\n",
      "133/133 [==============================] - 5s 34ms/step - loss: 4.0367 - accuracy: 0.0635 - val_loss: 2.9484 - val_accuracy: 0.1007\n",
      "Epoch 2/10\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 2.6329 - accuracy: 0.1935 - val_loss: 2.0440 - val_accuracy: 0.3987\n",
      "Epoch 3/10\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 1.8676 - accuracy: 0.4128 - val_loss: 1.4396 - val_accuracy: 0.5887\n",
      "Epoch 4/10\n",
      "133/133 [==============================] - 4s 31ms/step - loss: 1.4061 - accuracy: 0.5555 - val_loss: 1.1778 - val_accuracy: 0.6607\n",
      "Epoch 5/10\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 1.1629 - accuracy: 0.6262 - val_loss: 1.0463 - val_accuracy: 0.6927\n",
      "Epoch 6/10\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 0.9753 - accuracy: 0.6933 - val_loss: 0.9308 - val_accuracy: 0.7260\n",
      "Epoch 7/10\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 0.8336 - accuracy: 0.7309 - val_loss: 0.8630 - val_accuracy: 0.7493\n",
      "Epoch 8/10\n",
      "133/133 [==============================] - 4s 31ms/step - loss: 0.7124 - accuracy: 0.7726 - val_loss: 0.8105 - val_accuracy: 0.7647\n",
      "Epoch 9/10\n",
      "133/133 [==============================] - 4s 33ms/step - loss: 0.6215 - accuracy: 0.7970 - val_loss: 0.7675 - val_accuracy: 0.7640\n",
      "Epoch 10/10\n",
      "133/133 [==============================] - 3s 26ms/step - loss: 0.5267 - accuracy: 0.8303 - val_loss: 0.7576 - val_accuracy: 0.7707\n",
      "Epoch 1/5\n",
      "133/133 [==============================] - 17s 124ms/step - loss: 0.4523 - accuracy: 0.8595 - val_loss: 0.7431 - val_accuracy: 0.7753\n",
      "Epoch 2/5\n",
      "133/133 [==============================] - 14s 109ms/step - loss: 0.4409 - accuracy: 0.8601 - val_loss: 0.7345 - val_accuracy: 0.7767\n",
      "Epoch 3/5\n",
      "133/133 [==============================] - 16s 123ms/step - loss: 0.4212 - accuracy: 0.8665 - val_loss: 0.7274 - val_accuracy: 0.7773\n",
      "Epoch 4/5\n",
      "133/133 [==============================] - 16s 117ms/step - loss: 0.4221 - accuracy: 0.8623 - val_loss: 0.7246 - val_accuracy: 0.7787\n",
      "Epoch 5/5\n",
      "133/133 [==============================] - 15s 115ms/step - loss: 0.4278 - accuracy: 0.8632 - val_loss: 0.7182 - val_accuracy: 0.7807\n",
      "47/47 [==============================] - 1s 12ms/step\n",
      "\n",
      "Character 4\n",
      "Epoch 1/10\n",
      "133/133 [==============================] - 5s 36ms/step - loss: 4.0849 - accuracy: 0.0603 - val_loss: 2.9858 - val_accuracy: 0.0887\n",
      "Epoch 2/10\n",
      "133/133 [==============================] - 4s 33ms/step - loss: 2.8584 - accuracy: 0.1312 - val_loss: 2.6324 - val_accuracy: 0.1947\n",
      "Epoch 3/10\n",
      "133/133 [==============================] - 4s 33ms/step - loss: 2.3412 - accuracy: 0.2787 - val_loss: 1.9460 - val_accuracy: 0.4073\n",
      "Epoch 4/10\n",
      "133/133 [==============================] - 5s 35ms/step - loss: 1.7900 - accuracy: 0.4348 - val_loss: 1.4714 - val_accuracy: 0.5560\n",
      "Epoch 5/10\n",
      "133/133 [==============================] - 4s 27ms/step - loss: 1.4432 - accuracy: 0.5408 - val_loss: 1.2576 - val_accuracy: 0.6173\n",
      "Epoch 6/10\n",
      "133/133 [==============================] - 4s 27ms/step - loss: 1.2156 - accuracy: 0.6168 - val_loss: 1.1092 - val_accuracy: 0.6660\n",
      "Epoch 7/10\n",
      "133/133 [==============================] - 5s 34ms/step - loss: 1.0537 - accuracy: 0.6635 - val_loss: 1.0112 - val_accuracy: 0.6987\n",
      "Epoch 8/10\n",
      "133/133 [==============================] - 4s 27ms/step - loss: 0.9001 - accuracy: 0.7112 - val_loss: 0.9428 - val_accuracy: 0.7140\n",
      "Epoch 9/10\n",
      "133/133 [==============================] - 5s 35ms/step - loss: 0.7880 - accuracy: 0.7532 - val_loss: 0.8938 - val_accuracy: 0.7320\n",
      "Epoch 10/10\n",
      "133/133 [==============================] - 3s 25ms/step - loss: 0.7195 - accuracy: 0.7626 - val_loss: 0.8568 - val_accuracy: 0.7293\n",
      "Epoch 1/5\n",
      "133/133 [==============================] - 17s 123ms/step - loss: 0.6373 - accuracy: 0.7924 - val_loss: 0.8398 - val_accuracy: 0.7353\n",
      "Epoch 2/5\n",
      "133/133 [==============================] - 16s 122ms/step - loss: 0.6113 - accuracy: 0.8046 - val_loss: 0.8289 - val_accuracy: 0.7420\n",
      "Epoch 3/5\n",
      "133/133 [==============================] - 17s 126ms/step - loss: 0.5941 - accuracy: 0.8070 - val_loss: 0.8261 - val_accuracy: 0.7400\n",
      "Epoch 4/5\n",
      "133/133 [==============================] - 15s 115ms/step - loss: 0.5982 - accuracy: 0.8104 - val_loss: 0.8228 - val_accuracy: 0.7407\n",
      "Epoch 5/5\n",
      "133/133 [==============================] - 15s 116ms/step - loss: 0.5975 - accuracy: 0.8130 - val_loss: 0.8143 - val_accuracy: 0.7413\n",
      "47/47 [==============================] - 1s 13ms/step\n",
      "\n",
      "Character 5\n",
      "Epoch 1/10\n",
      "133/133 [==============================] - 5s 35ms/step - loss: 4.1207 - accuracy: 0.0535 - val_loss: 3.0378 - val_accuracy: 0.0780\n",
      "Epoch 2/10\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 2.9720 - accuracy: 0.0993 - val_loss: 2.6900 - val_accuracy: 0.1800\n",
      "Epoch 3/10\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 2.4963 - accuracy: 0.2233 - val_loss: 2.1017 - val_accuracy: 0.3693\n",
      "Epoch 4/10\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 2.0114 - accuracy: 0.3713 - val_loss: 1.6010 - val_accuracy: 0.5173\n",
      "Epoch 5/10\n",
      "133/133 [==============================] - 4s 27ms/step - loss: 1.6601 - accuracy: 0.4698 - val_loss: 1.3310 - val_accuracy: 0.6120\n",
      "Epoch 6/10\n",
      "133/133 [==============================] - 3s 26ms/step - loss: 1.4258 - accuracy: 0.5439 - val_loss: 1.1742 - val_accuracy: 0.6527\n",
      "Epoch 7/10\n",
      "133/133 [==============================] - 3s 26ms/step - loss: 1.2394 - accuracy: 0.6015 - val_loss: 1.0468 - val_accuracy: 0.6847\n",
      "Epoch 8/10\n",
      "133/133 [==============================] - 3s 25ms/step - loss: 1.0751 - accuracy: 0.6552 - val_loss: 0.9403 - val_accuracy: 0.7287\n",
      "Epoch 9/10\n",
      "133/133 [==============================] - 3s 25ms/step - loss: 0.9734 - accuracy: 0.6870 - val_loss: 0.8968 - val_accuracy: 0.7373\n",
      "Epoch 10/10\n",
      "133/133 [==============================] - 3s 24ms/step - loss: 0.8790 - accuracy: 0.7145 - val_loss: 0.8349 - val_accuracy: 0.7467\n",
      "Epoch 1/5\n",
      "133/133 [==============================] - 15s 112ms/step - loss: 0.7697 - accuracy: 0.7517 - val_loss: 0.8245 - val_accuracy: 0.7527\n",
      "Epoch 2/5\n",
      "133/133 [==============================] - 14s 106ms/step - loss: 0.7703 - accuracy: 0.7520 - val_loss: 0.8148 - val_accuracy: 0.7573\n",
      "Epoch 3/5\n",
      "133/133 [==============================] - 16s 118ms/step - loss: 0.7598 - accuracy: 0.7546 - val_loss: 0.8074 - val_accuracy: 0.7580\n",
      "Epoch 4/5\n",
      "133/133 [==============================] - 16s 119ms/step - loss: 0.7455 - accuracy: 0.7554 - val_loss: 0.8019 - val_accuracy: 0.7560\n",
      "Epoch 5/5\n",
      "133/133 [==============================] - 16s 121ms/step - loss: 0.7563 - accuracy: 0.7543 - val_loss: 0.7972 - val_accuracy: 0.7607\n",
      "47/47 [==============================] - 1s 16ms/step\n",
      "\n",
      "Character 6\n",
      "Epoch 1/10\n",
      "133/133 [==============================] - 5s 37ms/step - loss: 3.9559 - accuracy: 0.0579 - val_loss: 3.0299 - val_accuracy: 0.0687\n",
      "Epoch 2/10\n",
      "133/133 [==============================] - 3s 25ms/step - loss: 3.0180 - accuracy: 0.0876 - val_loss: 2.8350 - val_accuracy: 0.1407\n",
      "Epoch 3/10\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 2.5806 - accuracy: 0.2099 - val_loss: 2.1071 - val_accuracy: 0.3707\n",
      "Epoch 4/10\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 1.8814 - accuracy: 0.3960 - val_loss: 1.3761 - val_accuracy: 0.5873\n",
      "Epoch 5/10\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 1.4273 - accuracy: 0.5397 - val_loss: 0.9899 - val_accuracy: 0.7247\n",
      "Epoch 6/10\n",
      "133/133 [==============================] - 4s 30ms/step - loss: 1.1158 - accuracy: 0.6356 - val_loss: 0.7905 - val_accuracy: 0.7853\n",
      "Epoch 7/10\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 0.9295 - accuracy: 0.6952 - val_loss: 0.6730 - val_accuracy: 0.8107\n",
      "Epoch 8/10\n",
      "133/133 [==============================] - 3s 26ms/step - loss: 0.7810 - accuracy: 0.7418 - val_loss: 0.5853 - val_accuracy: 0.8267\n",
      "Epoch 9/10\n",
      "133/133 [==============================] - 3s 24ms/step - loss: 0.6806 - accuracy: 0.7738 - val_loss: 0.5406 - val_accuracy: 0.8393\n",
      "Epoch 10/10\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 0.6065 - accuracy: 0.8053 - val_loss: 0.4846 - val_accuracy: 0.8473\n",
      "Epoch 1/5\n",
      "133/133 [==============================] - 16s 115ms/step - loss: 0.5405 - accuracy: 0.8233 - val_loss: 0.4696 - val_accuracy: 0.8553\n",
      "Epoch 2/5\n",
      "133/133 [==============================] - 17s 126ms/step - loss: 0.5433 - accuracy: 0.8219 - val_loss: 0.4625 - val_accuracy: 0.8547\n",
      "Epoch 3/5\n",
      "133/133 [==============================] - 16s 119ms/step - loss: 0.5344 - accuracy: 0.8250 - val_loss: 0.4595 - val_accuracy: 0.8520\n",
      "Epoch 4/5\n",
      "133/133 [==============================] - 17s 127ms/step - loss: 0.5100 - accuracy: 0.8293 - val_loss: 0.4528 - val_accuracy: 0.8547\n",
      "Epoch 5/5\n",
      "133/133 [==============================] - 18s 132ms/step - loss: 0.5093 - accuracy: 0.8334 - val_loss: 0.4498 - val_accuracy: 0.8567\n",
      "47/47 [==============================] - 1s 11ms/step\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train all models\n",
    "def train_model(X_train, X_test, y_train, y_test):\n",
    "    # Clear the current model\n",
    "    keras.backend.clear_session()\n",
    "    \n",
    "    # Store test results\n",
    "    results = np.zeros((y_test[0].shape[0], 6), dtype=object)\n",
    "    \n",
    "    # Hyperparameters\n",
    "    filters = 32\n",
    "    shape = 5\n",
    "    stride = 2\n",
    "    pad ='same'\n",
    "    act = 'relu'    \n",
    "    n_classes = y_train[0].shape[1]\n",
    "    \n",
    "    # Layers to be frozen\n",
    "    feature_layers = [\n",
    "        Conv2D(filters, shape, strides=stride, padding=pad, activation=act,\n",
    "               input_shape=X_train.shape[1:]),\n",
    "        Conv2D(filters, shape, strides=stride, padding=pad, activation=act),\n",
    "        Conv2D(filters, shape, strides=stride, padding=pad, activation=act),\n",
    "        MaxPooling2D(pool_size=2),\n",
    "        Dropout(0.25),\n",
    "        Flatten()\n",
    "    ]\n",
    "    \n",
    "    # Classification layers\n",
    "    class_layers = [\n",
    "        Dense(512, activation=act),\n",
    "        Dropout(0.25),\n",
    "        Dense(n_classes, activation='softmax')\n",
    "    ]\n",
    "\n",
    "    # Simple CNN\n",
    "    model = Sequential(feature_layers + class_layers)\n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    print(\"Character 1\")\n",
    "    model.fit(X_train, y_train[0],\n",
    "                  batch_size=64,\n",
    "                  epochs=15,\n",
    "                  validation_data=(X_test, y_test[0]),\n",
    "                  shuffle=True)\n",
    "    \n",
    "    # Save the prediction results\n",
    "    y_pred = pred_classes(model.predict(X_test))\n",
    "    results[:,0] = encoder.inverse_transform(y_pred).flatten()\n",
    "    print()\n",
    "    \n",
    "    # Freeze the feature layers\n",
    "    for l in feature_layers:\n",
    "        l.trainable = False\n",
    "        \n",
    "    # Train the rest of the models using the frozen layers\n",
    "    for i in range(1,6):\n",
    "        print(f\"Character {i+1}\")\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        model.fit(X_train, y_train[i],\n",
    "                  batch_size=64,\n",
    "                  epochs=10,\n",
    "                  validation_data=(X_test, y_test[i]),\n",
    "                  shuffle=True)\n",
    "        \n",
    "        # Fine tuning\n",
    "        for l in feature_layers:\n",
    "            l.trainable = True\n",
    "        learn_rate = 1e-5\n",
    "        model.compile(loss='categorical_crossentropy', \n",
    "                      optimizer=keras.optimizers.Adam(learn_rate),\n",
    "                      metrics=['accuracy'])\n",
    "        model.fit(X_train, y_train[i],\n",
    "                  batch_size=64,\n",
    "                  epochs=5,\n",
    "                  validation_data=(X_test, y_test[i]),\n",
    "                  shuffle=True)\n",
    "        \n",
    "        for l in feature_layers:\n",
    "            l.trainable = False\n",
    "        \n",
    "        y_pred = pred_classes(model.predict(X_test))\n",
    "        results[:,i] = encoder.inverse_transform(y_pred).flatten()\n",
    "        print()\n",
    "\n",
    "    return results\n",
    "\n",
    "results_3 = train_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7c28f7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per Character Accuracy: 81.67%\n",
      "Per Label Accuracy: 39.40%\n"
     ]
    }
   ],
   "source": [
    "label_accuracy(labels_test, results_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87651153",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 25, 125, 32)       832       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 63, 32)        25632     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 7, 32, 32)         25632     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 3, 16, 32)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 3, 16, 32)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1536)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               786944    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 21)                5397      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 975,765\n",
      "Trainable params: 975,765\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Character 1\n",
      "Epoch 1/15\n",
      "133/133 [==============================] - 19s 141ms/step - loss: 3.0456 - accuracy: 0.0451 - val_loss: 3.0428 - val_accuracy: 0.0713\n",
      "Epoch 2/15\n",
      "133/133 [==============================] - 16s 119ms/step - loss: 2.6977 - accuracy: 0.1399 - val_loss: 2.1081 - val_accuracy: 0.3113\n",
      "Epoch 3/15\n",
      "133/133 [==============================] - 20s 152ms/step - loss: 1.6532 - accuracy: 0.4395 - val_loss: 1.0905 - val_accuracy: 0.6207\n",
      "Epoch 4/15\n",
      "133/133 [==============================] - 19s 140ms/step - loss: 0.8346 - accuracy: 0.7143 - val_loss: 0.5416 - val_accuracy: 0.8153\n",
      "Epoch 5/15\n",
      "133/133 [==============================] - 19s 142ms/step - loss: 0.5168 - accuracy: 0.8213 - val_loss: 0.3672 - val_accuracy: 0.8813\n",
      "Epoch 6/15\n",
      "133/133 [==============================] - 18s 136ms/step - loss: 0.3469 - accuracy: 0.8813 - val_loss: 0.2704 - val_accuracy: 0.9160\n",
      "Epoch 7/15\n",
      "133/133 [==============================] - 19s 146ms/step - loss: 0.2520 - accuracy: 0.9147 - val_loss: 0.2357 - val_accuracy: 0.9307\n",
      "Epoch 8/15\n",
      "133/133 [==============================] - 16s 121ms/step - loss: 0.2101 - accuracy: 0.9254 - val_loss: 0.2060 - val_accuracy: 0.9373\n",
      "Epoch 9/15\n",
      "133/133 [==============================] - 18s 136ms/step - loss: 0.1698 - accuracy: 0.9455 - val_loss: 0.1937 - val_accuracy: 0.9360\n",
      "Epoch 10/15\n",
      "133/133 [==============================] - 19s 142ms/step - loss: 0.1397 - accuracy: 0.9526 - val_loss: 0.1948 - val_accuracy: 0.9407\n",
      "Epoch 11/15\n",
      "133/133 [==============================] - 16s 122ms/step - loss: 0.1310 - accuracy: 0.9552 - val_loss: 0.1950 - val_accuracy: 0.9373\n",
      "Epoch 12/15\n",
      "133/133 [==============================] - 19s 140ms/step - loss: 0.1103 - accuracy: 0.9608 - val_loss: 0.1730 - val_accuracy: 0.9507\n",
      "Epoch 13/15\n",
      "133/133 [==============================] - 20s 151ms/step - loss: 0.0784 - accuracy: 0.9735 - val_loss: 0.2045 - val_accuracy: 0.9393\n",
      "Epoch 14/15\n",
      "133/133 [==============================] - 19s 142ms/step - loss: 0.0943 - accuracy: 0.9673 - val_loss: 0.1789 - val_accuracy: 0.9487\n",
      "Epoch 15/15\n",
      "133/133 [==============================] - 15s 111ms/step - loss: 0.0689 - accuracy: 0.9782 - val_loss: 0.2119 - val_accuracy: 0.9340\n",
      "47/47 [==============================] - 1s 14ms/step\n",
      "\n",
      "Character 2\n",
      "Epoch 1/10\n",
      "133/133 [==============================] - 5s 38ms/step - loss: 4.0452 - accuracy: 0.1232 - val_loss: 2.1874 - val_accuracy: 0.3460\n",
      "Epoch 2/10\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 1.8775 - accuracy: 0.4022 - val_loss: 1.2372 - val_accuracy: 0.6320\n",
      "Epoch 3/10\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 1.3069 - accuracy: 0.5775 - val_loss: 0.9179 - val_accuracy: 0.7307\n",
      "Epoch 4/10\n",
      "133/133 [==============================] - 4s 33ms/step - loss: 1.0483 - accuracy: 0.6527 - val_loss: 0.7813 - val_accuracy: 0.7620\n",
      "Epoch 5/10\n",
      "133/133 [==============================] - 4s 34ms/step - loss: 0.8461 - accuracy: 0.7254 - val_loss: 0.6594 - val_accuracy: 0.7987\n",
      "Epoch 6/10\n",
      "133/133 [==============================] - 4s 33ms/step - loss: 0.6982 - accuracy: 0.7705 - val_loss: 0.6070 - val_accuracy: 0.8127\n",
      "Epoch 7/10\n",
      "133/133 [==============================] - 4s 31ms/step - loss: 0.5899 - accuracy: 0.8053 - val_loss: 0.5563 - val_accuracy: 0.8253\n",
      "Epoch 8/10\n",
      "133/133 [==============================] - 4s 30ms/step - loss: 0.5306 - accuracy: 0.8230 - val_loss: 0.5225 - val_accuracy: 0.8367\n",
      "Epoch 9/10\n",
      "133/133 [==============================] - 5s 36ms/step - loss: 0.4557 - accuracy: 0.8495 - val_loss: 0.5171 - val_accuracy: 0.8367\n",
      "Epoch 10/10\n",
      "133/133 [==============================] - 3s 25ms/step - loss: 0.3933 - accuracy: 0.8688 - val_loss: 0.5004 - val_accuracy: 0.8467\n",
      "Epoch 1/5\n",
      "133/133 [==============================] - 18s 127ms/step - loss: 0.3200 - accuracy: 0.8982 - val_loss: 0.4801 - val_accuracy: 0.8513\n",
      "Epoch 2/5\n",
      "133/133 [==============================] - 14s 107ms/step - loss: 0.3148 - accuracy: 0.8985 - val_loss: 0.4659 - val_accuracy: 0.8573\n",
      "Epoch 3/5\n",
      "133/133 [==============================] - 18s 138ms/step - loss: 0.3065 - accuracy: 0.8975 - val_loss: 0.4560 - val_accuracy: 0.8573\n",
      "Epoch 4/5\n",
      "133/133 [==============================] - 17s 126ms/step - loss: 0.2881 - accuracy: 0.9093 - val_loss: 0.4506 - val_accuracy: 0.8573\n",
      "Epoch 5/5\n",
      "133/133 [==============================] - 16s 123ms/step - loss: 0.2899 - accuracy: 0.9067 - val_loss: 0.4446 - val_accuracy: 0.8600\n",
      "47/47 [==============================] - 1s 13ms/step\n",
      "\n",
      "Character 3\n",
      "Epoch 1/10\n",
      "133/133 [==============================] - 6s 40ms/step - loss: 3.7020 - accuracy: 0.0808 - val_loss: 2.7542 - val_accuracy: 0.1713\n",
      "Epoch 2/10\n",
      "133/133 [==============================] - 4s 30ms/step - loss: 2.3202 - accuracy: 0.2771 - val_loss: 1.7087 - val_accuracy: 0.4720\n",
      "Epoch 3/10\n",
      "133/133 [==============================] - 4s 30ms/step - loss: 1.5923 - accuracy: 0.4835 - val_loss: 1.1808 - val_accuracy: 0.6500\n",
      "Epoch 4/10\n",
      "133/133 [==============================] - 4s 27ms/step - loss: 1.1946 - accuracy: 0.6070 - val_loss: 0.9637 - val_accuracy: 0.7033\n",
      "Epoch 5/10\n",
      "133/133 [==============================] - 4s 31ms/step - loss: 0.9710 - accuracy: 0.6780 - val_loss: 0.8252 - val_accuracy: 0.7367\n",
      "Epoch 6/10\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 0.8043 - accuracy: 0.7378 - val_loss: 0.7422 - val_accuracy: 0.7620\n",
      "Epoch 7/10\n",
      "133/133 [==============================] - 4s 31ms/step - loss: 0.6861 - accuracy: 0.7700 - val_loss: 0.7015 - val_accuracy: 0.7887\n",
      "Epoch 8/10\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 0.5832 - accuracy: 0.8101 - val_loss: 0.6634 - val_accuracy: 0.7887\n",
      "Epoch 9/10\n",
      "133/133 [==============================] - 4s 27ms/step - loss: 0.4949 - accuracy: 0.8354 - val_loss: 0.6322 - val_accuracy: 0.7980\n",
      "Epoch 10/10\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 0.4604 - accuracy: 0.8461 - val_loss: 0.6428 - val_accuracy: 0.8000\n",
      "Epoch 1/5\n",
      "133/133 [==============================] - 17s 124ms/step - loss: 0.3727 - accuracy: 0.8760 - val_loss: 0.6199 - val_accuracy: 0.8080\n",
      "Epoch 2/5\n",
      "133/133 [==============================] - 16s 121ms/step - loss: 0.3677 - accuracy: 0.8788 - val_loss: 0.6057 - val_accuracy: 0.8140\n",
      "Epoch 3/5\n",
      "133/133 [==============================] - 17s 127ms/step - loss: 0.3639 - accuracy: 0.8780 - val_loss: 0.5964 - val_accuracy: 0.8180\n",
      "Epoch 4/5\n",
      "133/133 [==============================] - 18s 134ms/step - loss: 0.3539 - accuracy: 0.8834 - val_loss: 0.5928 - val_accuracy: 0.8207\n",
      "Epoch 5/5\n",
      "133/133 [==============================] - 15s 112ms/step - loss: 0.3506 - accuracy: 0.8844 - val_loss: 0.5864 - val_accuracy: 0.8220\n",
      "47/47 [==============================] - 1s 11ms/step\n",
      "\n",
      "Character 4\n",
      "Epoch 1/10\n",
      "133/133 [==============================] - 6s 42ms/step - loss: 3.8086 - accuracy: 0.0858 - val_loss: 2.7449 - val_accuracy: 0.1460\n",
      "Epoch 2/10\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 2.4997 - accuracy: 0.2167 - val_loss: 2.0573 - val_accuracy: 0.3620\n",
      "Epoch 3/10\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 1.9042 - accuracy: 0.3902 - val_loss: 1.5206 - val_accuracy: 0.5287\n",
      "Epoch 4/10\n",
      "133/133 [==============================] - 4s 27ms/step - loss: 1.4698 - accuracy: 0.5275 - val_loss: 1.2115 - val_accuracy: 0.6267\n",
      "Epoch 5/10\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 1.2042 - accuracy: 0.6084 - val_loss: 1.0098 - val_accuracy: 0.6800\n",
      "Epoch 6/10\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 1.0040 - accuracy: 0.6715 - val_loss: 0.9149 - val_accuracy: 0.7253\n",
      "Epoch 7/10\n",
      "133/133 [==============================] - 4s 34ms/step - loss: 0.8763 - accuracy: 0.7144 - val_loss: 0.8433 - val_accuracy: 0.7427\n",
      "Epoch 8/10\n",
      "133/133 [==============================] - 5s 38ms/step - loss: 0.7338 - accuracy: 0.7600 - val_loss: 0.7892 - val_accuracy: 0.7513\n",
      "Epoch 9/10\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 0.6708 - accuracy: 0.7827 - val_loss: 0.7370 - val_accuracy: 0.7667\n",
      "Epoch 10/10\n",
      "133/133 [==============================] - 4s 33ms/step - loss: 0.5784 - accuracy: 0.8091 - val_loss: 0.6874 - val_accuracy: 0.7820\n",
      "Epoch 1/5\n",
      "133/133 [==============================] - 18s 127ms/step - loss: 0.4929 - accuracy: 0.8365 - val_loss: 0.6755 - val_accuracy: 0.7833\n",
      "Epoch 2/5\n",
      "133/133 [==============================] - 17s 129ms/step - loss: 0.4761 - accuracy: 0.8426 - val_loss: 0.6690 - val_accuracy: 0.7847\n",
      "Epoch 3/5\n",
      "133/133 [==============================] - 20s 150ms/step - loss: 0.4627 - accuracy: 0.8470 - val_loss: 0.6678 - val_accuracy: 0.7893\n",
      "Epoch 4/5\n",
      "133/133 [==============================] - 16s 122ms/step - loss: 0.4606 - accuracy: 0.8497 - val_loss: 0.6617 - val_accuracy: 0.7893\n",
      "Epoch 5/5\n",
      "133/133 [==============================] - 17s 126ms/step - loss: 0.4596 - accuracy: 0.8510 - val_loss: 0.6568 - val_accuracy: 0.7933\n",
      "47/47 [==============================] - 0s 6ms/step\n",
      "\n",
      "Character 5\n",
      "Epoch 1/10\n",
      "133/133 [==============================] - 5s 34ms/step - loss: 3.8660 - accuracy: 0.0649 - val_loss: 2.9161 - val_accuracy: 0.1193\n",
      "Epoch 2/10\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 2.7158 - accuracy: 0.1580 - val_loss: 2.2974 - val_accuracy: 0.3180\n",
      "Epoch 3/10\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 2.1100 - accuracy: 0.3238 - val_loss: 1.6117 - val_accuracy: 0.5327\n",
      "Epoch 4/10\n",
      "133/133 [==============================] - 4s 33ms/step - loss: 1.6328 - accuracy: 0.4704 - val_loss: 1.2430 - val_accuracy: 0.6293\n",
      "Epoch 5/10\n",
      "133/133 [==============================] - 4s 30ms/step - loss: 1.3562 - accuracy: 0.5576 - val_loss: 1.0476 - val_accuracy: 0.6800\n",
      "Epoch 6/10\n",
      "133/133 [==============================] - 3s 25ms/step - loss: 1.1170 - accuracy: 0.6344 - val_loss: 0.8934 - val_accuracy: 0.7367\n",
      "Epoch 7/10\n",
      "133/133 [==============================] - 3s 26ms/step - loss: 0.9581 - accuracy: 0.6831 - val_loss: 0.7979 - val_accuracy: 0.7527\n",
      "Epoch 8/10\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 0.8500 - accuracy: 0.7189 - val_loss: 0.7294 - val_accuracy: 0.7747\n",
      "Epoch 9/10\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 0.7119 - accuracy: 0.7627 - val_loss: 0.6708 - val_accuracy: 0.7807\n",
      "Epoch 10/10\n",
      "133/133 [==============================] - 4s 27ms/step - loss: 0.6435 - accuracy: 0.7883 - val_loss: 0.6315 - val_accuracy: 0.7927\n",
      "Epoch 1/5\n",
      "133/133 [==============================] - 18s 131ms/step - loss: 0.5543 - accuracy: 0.8203 - val_loss: 0.6099 - val_accuracy: 0.8013\n",
      "Epoch 2/5\n",
      "133/133 [==============================] - 15s 113ms/step - loss: 0.5336 - accuracy: 0.8217 - val_loss: 0.6005 - val_accuracy: 0.8053\n",
      "Epoch 3/5\n",
      "133/133 [==============================] - 17s 127ms/step - loss: 0.5260 - accuracy: 0.8214 - val_loss: 0.5946 - val_accuracy: 0.8113\n",
      "Epoch 4/5\n",
      "133/133 [==============================] - 17s 127ms/step - loss: 0.5270 - accuracy: 0.8232 - val_loss: 0.5882 - val_accuracy: 0.8100\n",
      "Epoch 5/5\n",
      "133/133 [==============================] - 17s 130ms/step - loss: 0.5117 - accuracy: 0.8332 - val_loss: 0.5839 - val_accuracy: 0.8113\n",
      "47/47 [==============================] - 1s 10ms/step\n",
      "\n",
      "Character 6\n",
      "Epoch 1/10\n",
      "133/133 [==============================] - 6s 40ms/step - loss: 3.8818 - accuracy: 0.0712 - val_loss: 2.8121 - val_accuracy: 0.1353\n",
      "Epoch 2/10\n",
      "133/133 [==============================] - 4s 31ms/step - loss: 2.5467 - accuracy: 0.2115 - val_loss: 1.9907 - val_accuracy: 0.3940\n",
      "Epoch 3/10\n",
      "133/133 [==============================] - 4s 26ms/step - loss: 1.8229 - accuracy: 0.4035 - val_loss: 1.2477 - val_accuracy: 0.6073\n",
      "Epoch 4/10\n",
      "133/133 [==============================] - 5s 34ms/step - loss: 1.3296 - accuracy: 0.5590 - val_loss: 0.9276 - val_accuracy: 0.7147\n",
      "Epoch 5/10\n",
      "133/133 [==============================] - 3s 25ms/step - loss: 0.9850 - accuracy: 0.6783 - val_loss: 0.7018 - val_accuracy: 0.7867\n",
      "Epoch 6/10\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 0.7882 - accuracy: 0.7410 - val_loss: 0.5716 - val_accuracy: 0.8293\n",
      "Epoch 7/10\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 0.6548 - accuracy: 0.7804 - val_loss: 0.5079 - val_accuracy: 0.8520\n",
      "Epoch 8/10\n",
      "133/133 [==============================] - 4s 27ms/step - loss: 0.5586 - accuracy: 0.8096 - val_loss: 0.4584 - val_accuracy: 0.8560\n",
      "Epoch 9/10\n",
      "133/133 [==============================] - 3s 25ms/step - loss: 0.4649 - accuracy: 0.8424 - val_loss: 0.4229 - val_accuracy: 0.8720\n",
      "Epoch 10/10\n",
      "133/133 [==============================] - 3s 24ms/step - loss: 0.3988 - accuracy: 0.8658 - val_loss: 0.3891 - val_accuracy: 0.8733\n",
      "Epoch 1/5\n",
      "133/133 [==============================] - 18s 129ms/step - loss: 0.3553 - accuracy: 0.8792 - val_loss: 0.3747 - val_accuracy: 0.8820\n",
      "Epoch 2/5\n",
      "133/133 [==============================] - 15s 110ms/step - loss: 0.3473 - accuracy: 0.8861 - val_loss: 0.3678 - val_accuracy: 0.8847\n",
      "Epoch 3/5\n",
      "133/133 [==============================] - 18s 135ms/step - loss: 0.3181 - accuracy: 0.8933 - val_loss: 0.3640 - val_accuracy: 0.8867\n",
      "Epoch 4/5\n",
      "133/133 [==============================] - 17s 130ms/step - loss: 0.3224 - accuracy: 0.8931 - val_loss: 0.3612 - val_accuracy: 0.8887\n",
      "Epoch 5/5\n",
      "133/133 [==============================] - 17s 131ms/step - loss: 0.3154 - accuracy: 0.8954 - val_loss: 0.3569 - val_accuracy: 0.8920\n",
      "47/47 [==============================] - 1s 21ms/step\n",
      "\n",
      "Per Character Accuracy: 85.21%\n",
      "Per Label Accuracy: 45.80%\n"
     ]
    }
   ],
   "source": [
    "# Train all models\n",
    "def train_model(X_train, X_test, y_train, y_test):\n",
    "    # Clear the current model\n",
    "    keras.backend.clear_session()\n",
    "    \n",
    "    # Store test results\n",
    "    results = np.zeros((y_test[0].shape[0], 6), dtype=object)\n",
    "    \n",
    "    # Hyperparameters\n",
    "    filters = 32\n",
    "    shape = 5\n",
    "    stride = 2\n",
    "    pad ='same'\n",
    "    act = 'relu'    \n",
    "    n_classes = y_train[0].shape[1]\n",
    "    \n",
    "    # Layers to be frozen\n",
    "    feature_layers = [\n",
    "        Conv2D(filters, shape, strides=stride, padding=pad, activation=act,\n",
    "               input_shape=X_train.shape[1:]),\n",
    "        Conv2D(filters, shape, strides=stride, padding=pad, activation=act),\n",
    "        Conv2D(filters, shape, strides=stride, padding=pad, activation=act),\n",
    "        MaxPooling2D(pool_size=2),\n",
    "        Dropout(0.25),\n",
    "        Flatten()\n",
    "    ]\n",
    "    \n",
    "    # Classification layers\n",
    "    class_layers = [\n",
    "        Dense(512, activation=act),\n",
    "        Dropout(0.25),\n",
    "        Dense(256, activation=act),\n",
    "        Dense(n_classes, activation='softmax')\n",
    "    ]\n",
    "\n",
    "    # Simple CNN\n",
    "    model = Sequential(feature_layers + class_layers)\n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    print(\"Character 1\")\n",
    "    model.fit(X_train, y_train[0],\n",
    "                  batch_size=64,\n",
    "                  epochs=15,\n",
    "                  validation_data=(X_test, y_test[0]),\n",
    "                  shuffle=True)\n",
    "    \n",
    "    # Save the prediction results\n",
    "    y_pred = pred_classes(model.predict(X_test))\n",
    "    results[:,0] = encoder.inverse_transform(y_pred).flatten()\n",
    "    print()\n",
    "    \n",
    "    # Freeze the feature layers\n",
    "    for l in feature_layers:\n",
    "        l.trainable = False\n",
    "        \n",
    "    # Train the rest of the models using the frozen layers\n",
    "    for i in range(1,6):\n",
    "        print(f\"Character {i+1}\")\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        model.fit(X_train, y_train[i],\n",
    "                  batch_size=64,\n",
    "                  epochs=10,\n",
    "                  validation_data=(X_test, y_test[i]),\n",
    "                  shuffle=True)\n",
    "        \n",
    "        # Fine tuning\n",
    "        for l in feature_layers:\n",
    "            l.trainable = True\n",
    "        learn_rate = 1e-5\n",
    "        model.compile(loss='categorical_crossentropy', \n",
    "                      optimizer=keras.optimizers.Adam(learn_rate),\n",
    "                      metrics=['accuracy'])\n",
    "        model.fit(X_train, y_train[i],\n",
    "                  batch_size=64,\n",
    "                  epochs=5,\n",
    "                  validation_data=(X_test, y_test[i]),\n",
    "                  shuffle=True)\n",
    "        \n",
    "        for l in feature_layers:\n",
    "            l.trainable = False\n",
    "        \n",
    "        y_pred = pred_classes(model.predict(X_test))\n",
    "        results[:,i] = encoder.inverse_transform(y_pred).flatten()\n",
    "        print()\n",
    "\n",
    "    return results\n",
    "\n",
    "results_4 = train_model(X_train, X_test, y_train, y_test)\n",
    "label_accuracy(labels_test, results_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42d4884a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 25, 125, 32)       832       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 63, 32)        25632     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 7, 32, 32)         25632     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 3, 16, 32)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 3, 16, 32)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1536)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               786944    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 21)                2709      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,005,973\n",
      "Trainable params: 1,005,973\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Character 1\n",
      "Epoch 1/15\n",
      "133/133 [==============================] - 18s 128ms/step - loss: 3.0453 - accuracy: 0.0451 - val_loss: 3.0452 - val_accuracy: 0.0587\n",
      "Epoch 2/15\n",
      "133/133 [==============================] - 17s 130ms/step - loss: 2.9649 - accuracy: 0.0714 - val_loss: 2.6267 - val_accuracy: 0.1300\n",
      "Epoch 3/15\n",
      "133/133 [==============================] - 15s 111ms/step - loss: 2.3525 - accuracy: 0.1967 - val_loss: 1.8893 - val_accuracy: 0.3080\n",
      "Epoch 4/15\n",
      "133/133 [==============================] - 17s 128ms/step - loss: 1.6481 - accuracy: 0.3842 - val_loss: 1.1886 - val_accuracy: 0.5647\n",
      "Epoch 5/15\n",
      "133/133 [==============================] - 17s 124ms/step - loss: 1.0687 - accuracy: 0.5888 - val_loss: 0.7603 - val_accuracy: 0.7027\n",
      "Epoch 6/15\n",
      "133/133 [==============================] - 17s 131ms/step - loss: 0.7933 - accuracy: 0.6933 - val_loss: 0.6190 - val_accuracy: 0.7553\n",
      "Epoch 7/15\n",
      "133/133 [==============================] - 18s 133ms/step - loss: 0.5766 - accuracy: 0.7772 - val_loss: 0.4502 - val_accuracy: 0.8193\n",
      "Epoch 8/15\n",
      "133/133 [==============================] - 19s 140ms/step - loss: 0.4806 - accuracy: 0.8228 - val_loss: 0.4285 - val_accuracy: 0.8613\n",
      "Epoch 9/15\n",
      "133/133 [==============================] - 18s 136ms/step - loss: 0.3722 - accuracy: 0.8677 - val_loss: 0.3032 - val_accuracy: 0.8893\n",
      "Epoch 10/15\n",
      "133/133 [==============================] - 18s 132ms/step - loss: 0.2958 - accuracy: 0.8934 - val_loss: 0.2655 - val_accuracy: 0.9127\n",
      "Epoch 11/15\n",
      "133/133 [==============================] - 16s 124ms/step - loss: 0.2629 - accuracy: 0.9092 - val_loss: 0.2524 - val_accuracy: 0.9133\n",
      "Epoch 12/15\n",
      "133/133 [==============================] - 17s 126ms/step - loss: 0.2230 - accuracy: 0.9251 - val_loss: 0.3659 - val_accuracy: 0.8840\n",
      "Epoch 13/15\n",
      "133/133 [==============================] - 18s 135ms/step - loss: 0.2004 - accuracy: 0.9306 - val_loss: 0.3012 - val_accuracy: 0.9060\n",
      "Epoch 14/15\n",
      "133/133 [==============================] - 18s 133ms/step - loss: 0.1781 - accuracy: 0.9415 - val_loss: 0.2311 - val_accuracy: 0.9240\n",
      "Epoch 15/15\n",
      "133/133 [==============================] - 19s 142ms/step - loss: 0.1367 - accuracy: 0.9525 - val_loss: 0.2195 - val_accuracy: 0.9267\n",
      "47/47 [==============================] - 1s 25ms/step\n",
      "\n",
      "Character 2\n",
      "Epoch 1/10\n",
      "133/133 [==============================] - 6s 43ms/step - loss: 4.1537 - accuracy: 0.0652 - val_loss: 2.8786 - val_accuracy: 0.1187\n",
      "Epoch 2/10\n",
      "133/133 [==============================] - 4s 30ms/step - loss: 2.4615 - accuracy: 0.2017 - val_loss: 1.5886 - val_accuracy: 0.4827\n",
      "Epoch 3/10\n",
      "133/133 [==============================] - 4s 34ms/step - loss: 1.6631 - accuracy: 0.4228 - val_loss: 1.0839 - val_accuracy: 0.6493\n",
      "Epoch 4/10\n",
      "133/133 [==============================] - 4s 31ms/step - loss: 1.3208 - accuracy: 0.5446 - val_loss: 0.8741 - val_accuracy: 0.7227\n",
      "Epoch 5/10\n",
      "133/133 [==============================] - 4s 31ms/step - loss: 1.0931 - accuracy: 0.6215 - val_loss: 0.7651 - val_accuracy: 0.7393\n",
      "Epoch 6/10\n",
      "133/133 [==============================] - 4s 31ms/step - loss: 0.9497 - accuracy: 0.6713 - val_loss: 0.6675 - val_accuracy: 0.7793\n",
      "Epoch 7/10\n",
      "133/133 [==============================] - 4s 34ms/step - loss: 0.8167 - accuracy: 0.7190 - val_loss: 0.5854 - val_accuracy: 0.8087\n",
      "Epoch 8/10\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 0.7183 - accuracy: 0.7554 - val_loss: 0.5424 - val_accuracy: 0.8187\n",
      "Epoch 9/10\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 0.6633 - accuracy: 0.7740 - val_loss: 0.5196 - val_accuracy: 0.8340\n",
      "Epoch 10/10\n",
      "133/133 [==============================] - 4s 31ms/step - loss: 0.5871 - accuracy: 0.7976 - val_loss: 0.4882 - val_accuracy: 0.8387\n",
      "Epoch 1/5\n",
      "133/133 [==============================] - 20s 142ms/step - loss: 0.5234 - accuracy: 0.8208 - val_loss: 0.4669 - val_accuracy: 0.8460\n",
      "Epoch 2/5\n",
      "133/133 [==============================] - 15s 110ms/step - loss: 0.5064 - accuracy: 0.8275 - val_loss: 0.4575 - val_accuracy: 0.8520\n",
      "Epoch 3/5\n",
      "133/133 [==============================] - 16s 121ms/step - loss: 0.4836 - accuracy: 0.8346 - val_loss: 0.4518 - val_accuracy: 0.8560\n",
      "Epoch 4/5\n",
      "133/133 [==============================] - 16s 121ms/step - loss: 0.4862 - accuracy: 0.8344 - val_loss: 0.4465 - val_accuracy: 0.8567\n",
      "Epoch 5/5\n",
      "133/133 [==============================] - 15s 114ms/step - loss: 0.4629 - accuracy: 0.8420 - val_loss: 0.4433 - val_accuracy: 0.8560\n",
      "47/47 [==============================] - 1s 9ms/step\n",
      "\n",
      "Character 3\n",
      "Epoch 1/10\n",
      "133/133 [==============================] - 5s 37ms/step - loss: 3.5701 - accuracy: 0.0634 - val_loss: 2.8530 - val_accuracy: 0.1360\n",
      "Epoch 2/10\n",
      "133/133 [==============================] - 5s 34ms/step - loss: 2.4675 - accuracy: 0.2054 - val_loss: 1.8045 - val_accuracy: 0.3860\n",
      "Epoch 3/10\n",
      "133/133 [==============================] - 4s 33ms/step - loss: 1.8264 - accuracy: 0.3794 - val_loss: 1.3294 - val_accuracy: 0.5640\n",
      "Epoch 4/10\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 1.4797 - accuracy: 0.4778 - val_loss: 1.0787 - val_accuracy: 0.6273\n",
      "Epoch 5/10\n",
      "133/133 [==============================] - 4s 33ms/step - loss: 1.2354 - accuracy: 0.5753 - val_loss: 0.9405 - val_accuracy: 0.6807\n",
      "Epoch 6/10\n",
      "133/133 [==============================] - 4s 30ms/step - loss: 1.0541 - accuracy: 0.6330 - val_loss: 0.8231 - val_accuracy: 0.7200\n",
      "Epoch 7/10\n",
      "133/133 [==============================] - 4s 31ms/step - loss: 0.9215 - accuracy: 0.6843 - val_loss: 0.7385 - val_accuracy: 0.7480\n",
      "Epoch 8/10\n",
      "133/133 [==============================] - 4s 27ms/step - loss: 0.7933 - accuracy: 0.7277 - val_loss: 0.6854 - val_accuracy: 0.7607\n",
      "Epoch 9/10\n",
      "133/133 [==============================] - 4s 31ms/step - loss: 0.7059 - accuracy: 0.7623 - val_loss: 0.6602 - val_accuracy: 0.7753\n",
      "Epoch 10/10\n",
      "133/133 [==============================] - 4s 30ms/step - loss: 0.6485 - accuracy: 0.7853 - val_loss: 0.6298 - val_accuracy: 0.7820\n",
      "Epoch 1/5\n",
      "133/133 [==============================] - 19s 133ms/step - loss: 0.5558 - accuracy: 0.8134 - val_loss: 0.6107 - val_accuracy: 0.7873\n",
      "Epoch 2/5\n",
      "133/133 [==============================] - 19s 144ms/step - loss: 0.5508 - accuracy: 0.8114 - val_loss: 0.5979 - val_accuracy: 0.7900\n",
      "Epoch 3/5\n",
      "133/133 [==============================] - 18s 135ms/step - loss: 0.5426 - accuracy: 0.8131 - val_loss: 0.5895 - val_accuracy: 0.7920\n",
      "Epoch 4/5\n",
      "133/133 [==============================] - 19s 141ms/step - loss: 0.5390 - accuracy: 0.8137 - val_loss: 0.5846 - val_accuracy: 0.7960\n",
      "Epoch 5/5\n",
      "133/133 [==============================] - 17s 126ms/step - loss: 0.5136 - accuracy: 0.8259 - val_loss: 0.5809 - val_accuracy: 0.7973\n",
      "47/47 [==============================] - 2s 34ms/step\n",
      "\n",
      "Character 4\n",
      "Epoch 1/10\n",
      "133/133 [==============================] - 10s 38ms/step - loss: 3.6568 - accuracy: 0.0652 - val_loss: 2.9117 - val_accuracy: 0.1013\n",
      "Epoch 2/10\n",
      "133/133 [==============================] - 5s 34ms/step - loss: 2.6564 - accuracy: 0.1566 - val_loss: 2.1943 - val_accuracy: 0.3233\n",
      "Epoch 3/10\n",
      "133/133 [==============================] - 4s 30ms/step - loss: 2.0269 - accuracy: 0.3196 - val_loss: 1.5413 - val_accuracy: 0.5060\n",
      "Epoch 4/10\n",
      "133/133 [==============================] - 4s 31ms/step - loss: 1.6203 - accuracy: 0.4524 - val_loss: 1.2473 - val_accuracy: 0.5853\n",
      "Epoch 5/10\n",
      "133/133 [==============================] - 4s 33ms/step - loss: 1.3944 - accuracy: 0.5289 - val_loss: 1.1086 - val_accuracy: 0.6327\n",
      "Epoch 6/10\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 1.2198 - accuracy: 0.5868 - val_loss: 0.9593 - val_accuracy: 0.6727\n",
      "Epoch 7/10\n",
      "133/133 [==============================] - 4s 33ms/step - loss: 1.0749 - accuracy: 0.6385 - val_loss: 0.8897 - val_accuracy: 0.7053\n",
      "Epoch 8/10\n",
      "133/133 [==============================] - 5s 36ms/step - loss: 0.9525 - accuracy: 0.6747 - val_loss: 0.8446 - val_accuracy: 0.7253\n",
      "Epoch 9/10\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 0.8755 - accuracy: 0.7025 - val_loss: 0.7842 - val_accuracy: 0.7260\n",
      "Epoch 10/10\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 0.7486 - accuracy: 0.7477 - val_loss: 0.7377 - val_accuracy: 0.7473\n",
      "Epoch 1/5\n",
      "133/133 [==============================] - 18s 129ms/step - loss: 0.6921 - accuracy: 0.7663 - val_loss: 0.7261 - val_accuracy: 0.7487\n",
      "Epoch 2/5\n",
      "133/133 [==============================] - 19s 140ms/step - loss: 0.6918 - accuracy: 0.7664 - val_loss: 0.7178 - val_accuracy: 0.7527\n",
      "Epoch 3/5\n",
      "133/133 [==============================] - 19s 143ms/step - loss: 0.6507 - accuracy: 0.7792 - val_loss: 0.7097 - val_accuracy: 0.7560\n",
      "Epoch 4/5\n",
      "133/133 [==============================] - 19s 142ms/step - loss: 0.6580 - accuracy: 0.7820 - val_loss: 0.7030 - val_accuracy: 0.7573\n",
      "Epoch 5/5\n",
      "133/133 [==============================] - 18s 137ms/step - loss: 0.6499 - accuracy: 0.7833 - val_loss: 0.6977 - val_accuracy: 0.7627\n",
      "47/47 [==============================] - 1s 10ms/step\n",
      "\n",
      "Character 5\n",
      "Epoch 1/10\n",
      "133/133 [==============================] - 6s 42ms/step - loss: 3.6332 - accuracy: 0.0555 - val_loss: 3.0151 - val_accuracy: 0.0647\n",
      "Epoch 2/10\n",
      "133/133 [==============================] - 5s 39ms/step - loss: 2.8844 - accuracy: 0.1016 - val_loss: 2.5758 - val_accuracy: 0.2073\n",
      "Epoch 3/10\n",
      "133/133 [==============================] - 5s 37ms/step - loss: 2.3796 - accuracy: 0.2276 - val_loss: 1.8334 - val_accuracy: 0.4187\n",
      "Epoch 4/10\n",
      "133/133 [==============================] - 5s 37ms/step - loss: 1.8809 - accuracy: 0.3584 - val_loss: 1.3770 - val_accuracy: 0.5647\n",
      "Epoch 5/10\n",
      "133/133 [==============================] - 5s 34ms/step - loss: 1.5218 - accuracy: 0.4812 - val_loss: 1.1413 - val_accuracy: 0.6153\n",
      "Epoch 6/10\n",
      "133/133 [==============================] - 4s 30ms/step - loss: 1.3224 - accuracy: 0.5457 - val_loss: 0.9724 - val_accuracy: 0.6907\n",
      "Epoch 7/10\n",
      "133/133 [==============================] - 4s 30ms/step - loss: 1.1665 - accuracy: 0.6058 - val_loss: 0.8740 - val_accuracy: 0.7127\n",
      "Epoch 8/10\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 1.0402 - accuracy: 0.6426 - val_loss: 0.8149 - val_accuracy: 0.7393\n",
      "Epoch 9/10\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 0.9394 - accuracy: 0.6785 - val_loss: 0.7498 - val_accuracy: 0.7680\n",
      "Epoch 10/10\n",
      "133/133 [==============================] - 5s 37ms/step - loss: 0.8344 - accuracy: 0.7156 - val_loss: 0.6891 - val_accuracy: 0.7673\n",
      "Epoch 1/5\n",
      "133/133 [==============================] - 17s 125ms/step - loss: 0.7573 - accuracy: 0.7406 - val_loss: 0.6782 - val_accuracy: 0.7813\n",
      "Epoch 2/5\n",
      "133/133 [==============================] - 17s 125ms/step - loss: 0.7300 - accuracy: 0.7543 - val_loss: 0.6692 - val_accuracy: 0.7820\n",
      "Epoch 3/5\n",
      "133/133 [==============================] - 20s 152ms/step - loss: 0.7271 - accuracy: 0.7567 - val_loss: 0.6638 - val_accuracy: 0.7867\n",
      "Epoch 4/5\n",
      "133/133 [==============================] - 16s 118ms/step - loss: 0.7300 - accuracy: 0.7505 - val_loss: 0.6603 - val_accuracy: 0.7913\n",
      "Epoch 5/5\n",
      "133/133 [==============================] - 18s 133ms/step - loss: 0.7129 - accuracy: 0.7583 - val_loss: 0.6546 - val_accuracy: 0.7900\n",
      "47/47 [==============================] - 1s 18ms/step\n",
      "\n",
      "Character 6\n",
      "Epoch 1/10\n",
      "133/133 [==============================] - 6s 42ms/step - loss: 3.6691 - accuracy: 0.0547 - val_loss: 2.9820 - val_accuracy: 0.0800\n",
      "Epoch 2/10\n",
      "133/133 [==============================] - 4s 33ms/step - loss: 2.7214 - accuracy: 0.1405 - val_loss: 2.1390 - val_accuracy: 0.3440\n",
      "Epoch 3/10\n",
      "133/133 [==============================] - 5s 36ms/step - loss: 2.0652 - accuracy: 0.3108 - val_loss: 1.4966 - val_accuracy: 0.5347\n",
      "Epoch 4/10\n",
      "133/133 [==============================] - 5s 37ms/step - loss: 1.5743 - accuracy: 0.4532 - val_loss: 1.0699 - val_accuracy: 0.6433\n",
      "Epoch 5/10\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 1.2612 - accuracy: 0.5681 - val_loss: 0.8126 - val_accuracy: 0.7447\n",
      "Epoch 6/10\n",
      "133/133 [==============================] - 4s 33ms/step - loss: 1.0318 - accuracy: 0.6429 - val_loss: 0.6741 - val_accuracy: 0.8000\n",
      "Epoch 7/10\n",
      "133/133 [==============================] - 4s 33ms/step - loss: 0.8858 - accuracy: 0.6991 - val_loss: 0.5510 - val_accuracy: 0.8427\n",
      "Epoch 8/10\n",
      "133/133 [==============================] - 5s 35ms/step - loss: 0.7535 - accuracy: 0.7407 - val_loss: 0.5036 - val_accuracy: 0.8480\n",
      "Epoch 9/10\n",
      "133/133 [==============================] - 4s 30ms/step - loss: 0.6654 - accuracy: 0.7759 - val_loss: 0.4456 - val_accuracy: 0.8633\n",
      "Epoch 10/10\n",
      "133/133 [==============================] - 4s 30ms/step - loss: 0.5795 - accuracy: 0.8086 - val_loss: 0.4024 - val_accuracy: 0.8740\n",
      "Epoch 1/5\n",
      "133/133 [==============================] - 21s 154ms/step - loss: 0.5114 - accuracy: 0.8260 - val_loss: 0.3940 - val_accuracy: 0.8773\n",
      "Epoch 2/5\n",
      "133/133 [==============================] - 18s 135ms/step - loss: 0.4963 - accuracy: 0.8388 - val_loss: 0.3867 - val_accuracy: 0.8800\n",
      "Epoch 3/5\n",
      "133/133 [==============================] - 18s 132ms/step - loss: 0.4868 - accuracy: 0.8338 - val_loss: 0.3807 - val_accuracy: 0.8787\n",
      "Epoch 4/5\n",
      "133/133 [==============================] - 16s 124ms/step - loss: 0.4809 - accuracy: 0.8404 - val_loss: 0.3758 - val_accuracy: 0.8813\n",
      "Epoch 5/5\n",
      "133/133 [==============================] - 18s 137ms/step - loss: 0.4915 - accuracy: 0.8364 - val_loss: 0.3735 - val_accuracy: 0.8840\n",
      "47/47 [==============================] - 1s 16ms/step\n",
      "\n",
      "Per Character Accuracy: 83.61%\n",
      "Per Label Accuracy: 41.53%\n"
     ]
    }
   ],
   "source": [
    "# Train all models\n",
    "def train_model(X_train, X_test, y_train, y_test):\n",
    "    # Clear the current model\n",
    "    keras.backend.clear_session()\n",
    "    \n",
    "    # Store test results\n",
    "    results = np.zeros((y_test[0].shape[0], 6), dtype=object)\n",
    "    \n",
    "    # Hyperparameters\n",
    "    filters = 32\n",
    "    shape = 5\n",
    "    stride = 2\n",
    "    pad ='same'\n",
    "    act = 'relu'    \n",
    "    n_classes = y_train[0].shape[1]\n",
    "    \n",
    "    # Layers to be frozen\n",
    "    feature_layers = [\n",
    "        Conv2D(filters, shape, strides=stride, padding=pad, activation=act,\n",
    "               input_shape=X_train.shape[1:]),\n",
    "        Conv2D(filters, shape, strides=stride, padding=pad, activation=act),\n",
    "        Conv2D(filters, shape, strides=stride, padding=pad, activation=act),\n",
    "        MaxPooling2D(pool_size=2),\n",
    "        Dropout(0.25),\n",
    "        Flatten()\n",
    "    ]\n",
    "    \n",
    "    # Classification layers\n",
    "    class_layers = [\n",
    "        Dense(512, activation=act),\n",
    "        Dropout(0.25),\n",
    "        Dense(256, activation=act),\n",
    "        Dropout(0.25),\n",
    "        Dense(128, activation=act),\n",
    "        Dropout(0.25),\n",
    "        Dense(n_classes, activation='softmax')\n",
    "    ]\n",
    "\n",
    "    # Simple CNN\n",
    "    model = Sequential(feature_layers + class_layers)\n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    print(\"Character 1\")\n",
    "    model.fit(X_train, y_train[0],\n",
    "                  batch_size=64,\n",
    "                  epochs=15,\n",
    "                  validation_data=(X_test, y_test[0]),\n",
    "                  shuffle=True)\n",
    "    \n",
    "    # Save the prediction results\n",
    "    y_pred = pred_classes(model.predict(X_test))\n",
    "    results[:,0] = encoder.inverse_transform(y_pred).flatten()\n",
    "    print()\n",
    "    \n",
    "    # Freeze the feature layers\n",
    "    for l in feature_layers:\n",
    "        l.trainable = False\n",
    "        \n",
    "    # Train the rest of the models using the frozen layers\n",
    "    for i in range(1,6):\n",
    "        print(f\"Character {i+1}\")\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        model.fit(X_train, y_train[i],\n",
    "                  batch_size=64,\n",
    "                  epochs=10,\n",
    "                  validation_data=(X_test, y_test[i]),\n",
    "                  shuffle=True)\n",
    "        \n",
    "        # Fine tuning\n",
    "        for l in feature_layers:\n",
    "            l.trainable = True\n",
    "        learn_rate = 1e-5\n",
    "        model.compile(loss='categorical_crossentropy', \n",
    "                      optimizer=keras.optimizers.Adam(learn_rate),\n",
    "                      metrics=['accuracy'])\n",
    "        model.fit(X_train, y_train[i],\n",
    "                  batch_size=64,\n",
    "                  epochs=5,\n",
    "                  validation_data=(X_test, y_test[i]),\n",
    "                  shuffle=True)\n",
    "        \n",
    "        for l in feature_layers:\n",
    "            l.trainable = False\n",
    "        \n",
    "        y_pred = pred_classes(model.predict(X_test))\n",
    "        results[:,i] = encoder.inverse_transform(y_pred).flatten()\n",
    "        print()\n",
    "\n",
    "    return results\n",
    "\n",
    "results_4 = train_model(X_train, X_test, y_train, y_test)\n",
    "label_accuracy(labels_test, results_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600c76f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
